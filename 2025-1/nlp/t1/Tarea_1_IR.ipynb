{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 1: IntroducciÃ³n, Modelos de Espacio Vectorial, RecuperaciÃ³n de InformaciÃ³n y Modelos de Lenguaje\n",
        "\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - OtoÃ±o 2025)**\n",
        "\n",
        "## Tarjeta de IdentificaciÃ³n\n",
        "\n",
        "- **Nombre(s):** ```Israel Astudillo, Fabrizzio Pezolla, Rodrigo Molina```\n",
        "- **Fecha lÃ­mite de entrega ðŸ“†:** 15 de abril de 2025\n",
        "- **Tiempo estimado de dedicaciÃ³n:** 4 horas\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Instrucciones\n",
        "\n",
        "Â¡Bienvenid@s a la primera tarea del curso de *Natural Language Processing* (NLP)!\n",
        "\n",
        "El objetivo de esta tarea es evaluar los conceptos teÃ³ricos de las primeras semanas de clases, centrÃ¡ndose en:\n",
        "\n",
        "- **RecuperaciÃ³n de InformaciÃ³n (IR)**\n",
        "- **Modelos de Espacio Vectorial**\n",
        "- **Modelos de Lenguaje**\n",
        "\n",
        "Si aÃºn no has revisado el contenido correspondiente, se recomienda consultar las referencias disponibles al final del documento.\n",
        "\n",
        "### ðŸ“¢ Consideraciones generales\n",
        "\n",
        "âœ… La tarea debe realizarse en **grupos de hasta 3 personas**.\n",
        "\n",
        "âœ… La entrega debe realizarse a travÃ©s de **U-Cursos**, a mÃ¡s tardar en la fecha estipulada. **No se aceptarÃ¡n entregas atrasadas.**\n",
        "\n",
        "âœ… El formato de entrega es este mismo **Jupyter Notebook**.\n",
        "\n",
        "âœ… Su cÃ³digo serÃ¡ ejecutado al momento de la revisiÃ³n. **Verifiquen que no tenga errores de compilaciÃ³n.**\n",
        "\n",
        "âœ… Es obligatorio completar la **Tarjeta de IdentificaciÃ³n**. **No se asignarÃ¡ nota sin ella.**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“š Material de Referencia\n",
        "\n",
        "### ðŸ“„ Diapositivas del curso\n",
        "\n",
        "- [IntroducciÃ³n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Modelos de Espacio Vectorial y RecuperaciÃ³n de InformaciÃ³n](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)\n",
        "- [Modelos ProbabilÃ­sticos de Lenguaje](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
        "\n",
        "### ðŸ“º Videos del curso\n",
        "\n",
        "- **IntroducciÃ³n**: [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU) | [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- **RecuperaciÃ³n de InformaciÃ³n**: [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
        "- **Modelos ProbabilÃ­sticos de Lenguaje**: [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) | [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) | [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ“Œ **Recuerda:** La claridad y organizaciÃ³n en la entrega son clave para una mejor evaluaciÃ³n. Incluir analisis apropiado. Â¡Mucho Ã©xito! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7w4BT1qmChV"
      },
      "source": [
        "## P1. TokenizaciÃ³n\n",
        "\n",
        "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librerÃ­as que realicen este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgSZrB2oe1H",
        "outputId": "9557a6fc-6737-496d-dfb6-7688e14eece8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexiÃ³n drive-colab\n"
          ]
        }
      ],
      "source": [
        "# En caso de desarrollar la tarea desde colab, con el siguiente cÃ³digo podemos cargar los archivos desde drive:\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    path = '/content/drive/MyDrive/nlp/oh_algoritmo.txt'\n",
        "except:\n",
        "    print('Ignorando conexiÃ³n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCKFrnZcoy2F"
      },
      "source": [
        "Ejecute el cÃ³digo a continuaciÃ³n para cargar el ejemplo. Recuerde realizar la modificaciÃ³n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9CteGwEmDKw",
        "outputId": "70a2043b-4a15-4650-f75e-2d458494d63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"Â¡Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[RefrÃ¡n: Jorge Drexler]\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime quÃ© debo cantar\n",
            "Oh, algoritmo\n",
            "SÃ© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime quÃ© debo cantar\n",
            "Oh, algoritmo\n",
            "SÃ© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canciÃ³n\n",
            "Â¿QuÃ© algoritmo la pariÃ³?\n",
            "Me pregunto si fui yo\n",
            "Â¿La elegiste o te eligiÃ³?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con Ã‰l\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedrÃ­o es un cauce vacÃ­o\n",
            "Un barco que no tiene rÃ­o\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, tÃº tambiÃ©n\n",
            "Pero no queda claro quiÃ©n\n",
            "Tiene del mango a la sartÃ©n\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[RefrÃ¡n: Jorge Drexler]\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime quÃ© debo cantar)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(SÃ© que lo sabes mejor)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime quÃ© debo cantar)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(SÃ© que lo sabes mejor)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"OcurriÃ³ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPSSO2kJoArL"
      },
      "source": [
        "Fuente: https://genius.com/Jorge-drexler-oh-algoritmo-lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fG0hLbHg9dn"
      },
      "source": [
        "### Pregunta 1.a (0.25 puntos)\n",
        "\n",
        "DiseÃ±e una funciÃ³n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librerÃ­as con tokenizadores ya implementados. Puede utilizar la librerÃ­a **re** importada para trabajar sÃ­mbolos. Explique su razonamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5P7rk4VRm6Az"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qiRMkdjwazFT"
      },
      "outputs": [],
      "source": [
        "def get_tokens(texto):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    \"\"\"\n",
        "    get_tokens recibe un texto y entrega una lista con sus tokens.\n",
        "    [str]->list\n",
        "    \"\"\"\n",
        "    assert type(texto) == str, \"El texto debe ser un string\"\n",
        "    tokens = re.findall(r'\\w+|[^\\w\\s]', texto)\n",
        "    return tokens\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Of3bJ1tKo1Tp"
      },
      "outputs": [],
      "source": [
        "# FunciÃ³n get_tokens alternativa\n",
        "def get_tokens_alt(texto):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    \"\"\"\n",
        "    get_tokens recibe un texto y entrega una lista con sus tokens.\n",
        "    [str]->list\n",
        "    \"\"\"\n",
        "    assert type(texto) == str, \"El texto debe ser un string\"\n",
        "    tokens = texto.split(sep=\" \")\n",
        "    for i in range(len(tokens)):\n",
        "      token = tokens[i]\n",
        "      token_limpio = re.sub(r'[^a-zA-Z]', '', token).lower()\n",
        "      tokens[i] = token_limpio\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "hDBZn4kOm7uH",
        "outputId": "c4fabe68-1cb6-4f5a-d225-db9990779676"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['letra',\n",
              " 'de',\n",
              " 'oh',\n",
              " 'algoritmo',\n",
              " 'ft',\n",
              " 'nora',\n",
              " 'erezrefrn',\n",
              " 'jorge',\n",
              " 'drexlerquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroestribillo',\n",
              " 'jorge',\n",
              " 'drexlerdime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantaroh',\n",
              " 'algoritmos',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoverso',\n",
              " '',\n",
              " 'nora',\n",
              " 'erezwait',\n",
              " 'whats',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spentwhats',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'platedo',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'youve',\n",
              " 'been',\n",
              " 'fedare',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'baitmmm',\n",
              " 'im',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'i',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jailrather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bailto',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'facesso',\n",
              " 'im',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'massesthe',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'mainstreaming',\n",
              " 'like',\n",
              " 'grandes',\n",
              " 'bigass',\n",
              " 'ringscreaming',\n",
              " 'ill',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'willconscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'willconscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'willyou',\n",
              " 'might',\n",
              " 'also',\n",
              " 'likeamor',\n",
              " 'al',\n",
              " 'artejorge',\n",
              " 'drexlertinta',\n",
              " 'y',\n",
              " 'tiempojorge',\n",
              " 'drexlerasilojorge',\n",
              " 'drexlerpreestribillo',\n",
              " 'nora',\n",
              " 'erezso',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'i',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'i',\n",
              " 'wantcan',\n",
              " 'i',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quitestribillo',\n",
              " 'jorge',\n",
              " 'drexlerdime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantaroh',\n",
              " 'algoritmos',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoverso',\n",
              " '',\n",
              " 'jorge',\n",
              " 'drexlerpor',\n",
              " 'ejemplo',\n",
              " 'esta',\n",
              " 'cancinqu',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'parime',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yola',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligiverso',\n",
              " '',\n",
              " 'jorge',\n",
              " 'drexlerdios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papelya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " 'lfin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'luna',\n",
              " 'de',\n",
              " 'miely',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedro',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vacoun',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'roni',\n",
              " 'timonelverso',\n",
              " '',\n",
              " 'jorge',\n",
              " 'drexlertodos',\n",
              " 'aplauden',\n",
              " 't',\n",
              " 'tambinpero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'quintiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sartndel',\n",
              " 'sacrificiopiel',\n",
              " 'o',\n",
              " 'silicioy',\n",
              " 'el',\n",
              " 'precipiciodice',\n",
              " 'ven',\n",
              " 'ven',\n",
              " 'venrefrn',\n",
              " 'jorge',\n",
              " 'drexlerquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierodime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantarquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierooh',\n",
              " 'algoritmoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieros',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierodime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantarquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierooh',\n",
              " 'algoritmoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieros',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierowow']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens_alt(texto)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpZKljrotLa"
      },
      "source": [
        "### Pregunta 1.b (0.25 puntos)\n",
        "Explique su implementaciÃ³n aquÃ­:\n",
        "> La implementaciÃ³n utiliza la funciÃ³n .findall de la librerÃ­a re, que encuentra todas las apariciones del patrÃ³n expresado en el primer argumento, en forma de expresiÃ³n regular, en el texto insertado en el segundo argumento. La expresiÃ³n regular utilizada es `r'\\w+|[^\\w\\s]'`. La letra r sirve para que la expresiÃ³n no sea interpretada por python directamente como un comando y no utilice los sÃ­mbolos de escape como \"\\\" directamente, sino que la expresiÃ³n sea entregada tal cual. La expresiÃ³n se divide en dos partes por el sÃ­mbolo \"|\" que significa or lÃ³gico. La primera parte `\\w+` significa uno o mÃ¡s de un caracter alfanumÃ©rico de cualquier tipo, incluyendo guiones bajos. Esto captura conjuntos de letras como palabras y los distingue de cualquier otro separador como espacios, puntuaciones, entre otros. La segunda parte `[^\\w\\s]'` define una clase de caracteres con \"[ ]\", siendo la clase definida la negaciÃ³n (denotado con \"^\") de los caracteres alfanumÃ©ricos y espacios blancos de cualquier tipo como tab, saltos de lÃ­nea, entre otros. Es decir, esta clase captura todo lo que no sean caracteres alfanumÃ©ricos, guiones bajos y espacios blancos, lo cual deja solo los sÃ­mbolos de puntuaciÃ³n en general distinguidos como caracteres separados independientes. AsÃ­, en la salida de la funciÃ³n esperamos palabras y sÃ­mbolos de puntuaciÃ³n, que es el resultado que se obtuvo.\n",
        "\n",
        "> La implementaciÃ³n utiliza la funciÃ³n .split nativa de python para separar el string en strings mÃ¡s pequeÃ±os utilizando Ãºnicamente los espacios como separadores, retornando el resultado. Luego elimina todas los caracteres que no sean letras y transforma a minÃºscula el texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwAKWZvofEp"
      },
      "source": [
        "ImplementaciÃ³n con la libreria NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_GR2Z0lnnPB9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Letra',\n",
              " 'de',\n",
              " '\"Â¡',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'Algoritmo',\n",
              " '!\"',\n",
              " 'ft',\n",
              " '.',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " '[',\n",
              " 'RefrÃ¡n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'quÃ©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'SÃ©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '1',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'Wait',\n",
              " ',',\n",
              " 'what',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " '?',\n",
              " 'What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?',\n",
              " 'Mmm',\n",
              " ',',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " \"'\",\n",
              " 's',\n",
              " 'big',\n",
              " '-',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " ':',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " '[',\n",
              " 'Pre',\n",
              " '-',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'quÃ©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'SÃ©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '2',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " ',',\n",
              " 'esta',\n",
              " 'canciÃ³n',\n",
              " 'Â¿',\n",
              " 'QuÃ©',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'pariÃ³',\n",
              " '?',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " 'Â¿',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligiÃ³',\n",
              " '?',\n",
              " '[',\n",
              " 'Verso',\n",
              " '3',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " 'Ã‰l',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedrÃ­o',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vacÃ­o',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'rÃ­o',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " '[',\n",
              " 'Verso',\n",
              " '4',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " ',',\n",
              " 'tÃº',\n",
              " 'tambiÃ©n',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'quiÃ©n',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sartÃ©n',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " ':',\n",
              " 'Ven',\n",
              " ',',\n",
              " 'ven',\n",
              " ',',\n",
              " 'ven',\n",
              " '[',\n",
              " 'RefrÃ¡n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'quÃ©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'SÃ©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'quÃ©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'SÃ©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " 'Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Wow',\n",
              " ')']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(texto)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3P4OeGn-qo"
      },
      "source": [
        "### Pregunta 1.c (0.5 puntos)\n",
        "Â¿QuÃ© diferencias y similitudes encontrase al comparar la funciÃ³n de tokenizaciÃ³n creada manualmente por ti contra la implementaciÃ³n de NLTK, al tokenizar la letra de la canciÃ³n \"Oh, algoritmo\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12BZ29JoFCp"
      },
      "source": [
        "> La diferencia con la implementaciÃ³n de la librerÃ­a es que no se reconocen caracteres especiales y algunas palabras no se diferencian correctamente. Por ejemplo el token \"drexlerpreestribillo\" no es un token adecuado en comparaciÃ³n al resultado de la librerÃ­a, por lo que no es un muy buen resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmUULnB6hWcl"
      },
      "source": [
        "## P2. Stemming y Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskhxOLdpT9q"
      },
      "source": [
        "En esta secciÃ³n debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta secciÃ³n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hj07_CmwhYxk"
      },
      "outputs": [],
      "source": [
        "# Corpus en espaÃ±ol\n",
        "corpus_espanol = [\n",
        "    \"Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?\",\n",
        "    \"Dime quÃ© debo cantar\",\n",
        "    \"SÃ© que lo sabes mejor\"\n",
        "]\n",
        "\n",
        "# Corpus en inglÃ©s\n",
        "corpus_ingles = [\n",
        "    \"What's that sitting on your plate?\",\n",
        "    \"Do you want what you've been fed?\",\n",
        "    \"Are you the fish or bait?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRyOVbVWwJ5"
      },
      "source": [
        "### Pregunta 2.a (0.5 puntos)\n",
        "Implemente una funciÃ³n **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la funciÃ³n de la secciÃ³n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F-727zL3ptDZ"
      },
      "outputs": [],
      "source": [
        "def get_vocab(corpus):\n",
        "  ### AquÃ­ inicia tu cÃ³digo ###\n",
        "  \"\"\"\n",
        "  get_tokens recibe un texto y entrega una lista con sus tokens.\n",
        "  [str]->list\n",
        "  \"\"\"\n",
        "  assert type(corpus) == str, \"El texto debe ser un string\"\n",
        "  tokens = re.findall(r'\\w+|[^\\w\\s]', corpus)\n",
        "  return tokens\n",
        "  ### AquÃ­ termina tu cÃ³digo ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ge2cPS7fqYXy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Â¿',\n",
              " 'QuiÃ©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Dime',\n",
              " 'quÃ©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'SÃ©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_espanol = [get_vocab(vocab) for vocab in corpus_espanol]\n",
        "vocab_espanol = [palabra for sublista in vocab_espanol for palabra in sublista]\n",
        "vocab_espanol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFtzHUbzJqt"
      },
      "source": [
        "Resultado esperado (el orden puede variar):\n",
        "```\n",
        "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'SÃ©', 'que', 'quiere', 'quiero', 'sabes', 'QuiÃ©n', 'quiera', 'quÃ©']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "apRK_d8uqlSm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_ingles = [get_vocab(vocab) for vocab in corpus_ingles]\n",
        "vocab_ingles = [palabra for sublista in vocab_ingles for palabra in sublista]\n",
        "vocab_ingles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvWMUQq5zPP8"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVjU3cAzDkw"
      },
      "source": [
        "### Pregunta 2.b (0.5 puntos)\n",
        "Ahora diseÃ±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funciÃ³n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elecciÃ³n de stopwords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSeU-rDYbI1"
      },
      "source": [
        "    Explique sus reglas aquÃ­: Primero se aplicarÃ¡ stemming para homogenizar las palabras en el corpus, de forma de luego contar la frecuencia de cada palabra para identificar stopwords sobre los tokens homogenizados.\n",
        "    \n",
        "    Para hacer stemming en el corpus en espaÃ±ol identificamos los verbos conjugados y les quitamos sus extremos del final. Podemos lograr esto eliminando las vocales o vocales + \"s\" del final de palabras largas o de mÃ¡s de 4 caracteres.\n",
        "\n",
        "    En el corpus en inglÃ©s podemos eliminar las terminaciones \"ing\" en este corpus en especÃ­fico. PodrÃ­amos eliminar tambiÃ©n las \"s\" al final de las palabras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "777xbIG2sqy5"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocabulario, idioma):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
        "    new_vocab = vocabulario.copy()\n",
        "\n",
        "    # Eliminar tokens no alfanumÃ©ricos\n",
        "    new_vocab = [p for p in new_vocab if p.isalnum()]\n",
        "\n",
        "    if idioma == \"espanol\":\n",
        "        # Stemming espaÃ±ol\n",
        "        for i in range(len(new_vocab)):\n",
        "            palabra = new_vocab[i]\n",
        "            if len(palabra) >= 4:\n",
        "                if palabra[-1] == \"s\" and palabra[-2] in vowels:\n",
        "                    palabra = palabra[:-2]  # vocal + s\n",
        "                elif palabra[-1] in vowels:\n",
        "                    palabra = palabra[:-1]\n",
        "                elif palabra[-1] == \"s\":\n",
        "                    palabra = palabra[:-1]\n",
        "            new_vocab[i] = palabra\n",
        "\n",
        "    elif idioma == \"ingles\":\n",
        "        # Stemming inglÃ©s\n",
        "        for i in range(len(new_vocab)):\n",
        "            palabra = new_vocab[i]\n",
        "            if palabra.endswith(\"ing\") and len(palabra) > 4:\n",
        "                palabra = palabra[:-3]\n",
        "            elif palabra.endswith(\"s\") and len(palabra) > 3:\n",
        "                palabra = palabra[:-1]\n",
        "            new_vocab[i] = palabra\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Idioma no soportado\")\n",
        "\n",
        "    # Contar frecuencias para eliminar Stopwords\n",
        "    frec = {}\n",
        "    for palabra in new_vocab:\n",
        "        frec[palabra] = frec.get(palabra, 0) + 1\n",
        "\n",
        "    # Eliminar stopwords: palabras con >1 ocurrencia y largo <= 3\n",
        "    new_vocab = [p for p in new_vocab if not (frec[p] > 1 and len(p) <= 3)]\n",
        "    return new_vocab\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iT1Rr0das2Nb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario procesado en espaÃ±ol: ['QuiÃ©n', 'quier', 'yo', 'quier', 'cre', 'quier', 'Dim', 'quÃ©', 'deb', 'cantar', 'SÃ©', 'sab', 'mejor'] \n",
            "\n",
            "Vocabulario procesado en inglÃ©s: ['What', 's', 'that', 'sitt', 'on', 'your', 'plate', 'Do', 'want', 'what', 've', 'been', 'fed', 'Are', 'the', 'fish', 'or', 'bait'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
        "vocab_procesado_espanol = pre_processing(vocab_espanol, 'espanol')\n",
        "vocab_procesado_ingles = pre_processing(vocab_ingles, 'ingles')\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Vocabulario procesado en espaÃ±ol:\", vocab_procesado_espanol, \"\\n\")\n",
        "print(\"Vocabulario procesado en inglÃ©s:\", vocab_procesado_ingles, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajmn1HaNhZE9"
      },
      "source": [
        "## P3. Bag of Words (0.5 puntos)\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vT0XQM2Ghlvy"
      },
      "outputs": [],
      "source": [
        "d0 = 'El pÃ¡jaro come semillas'\n",
        "d1 = 'El pÃ¡jaro se despierta y canta'\n",
        "d2 = 'El pÃ¡jaro canta y come semillas'\n",
        "d3 = 'El pez come y nada en el agua'\n",
        "d4 = 'El pez empieza a nadar'\n",
        "d5 = 'El pez come alimento'\n",
        "corpus = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOOz1Su2ATf"
      },
      "source": [
        "El objetivo da las siguientes secciones es determinar cuÃ¡les de  los documentos entregados son los mÃ¡s similares entre sÃ­. Para ello utilizaremos la tÃ©cnica **TF-IDF**.\n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores numÃ©ricos. La representaciÃ³n mÃ¡s simple vista en clases es la de **Bag of Words**, mÃ©todo mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funciÃ³n **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representaciÃ³n Bag of Words de los documentos entregados. En esta representaciÃ³n las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
        "\n",
        "***Disclaimer: el orden de los resultados pueden variar.***\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente corpus:\n",
        "\n",
        "```\n",
        "corpus = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_njmcRPM2GpV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENCbDO8s_ls"
      },
      "source": [
        "Implementar funciÃ³n `bag_of_words()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C_eRRUvD2ChD"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(corpus):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    from collections import Counter\n",
        "\n",
        "    bow_repr = {\n",
        "        f'd{idx}': Counter(doc.split())\n",
        "        for idx, doc in enumerate(corpus)\n",
        "        }\n",
        "\n",
        "    return pd.DataFrame(bow_repr).T.fillna(0).astype(int)\n",
        "\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "jWZyXGra2FOw",
        "outputId": "46e4e450-a73b-45ae-9aa4-e178ff5184cb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "El",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "pÃ¡jaro",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "come",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "semillas",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "se",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "despierta",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "y",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "canta",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "pez",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "nada",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "en",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "el",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "agua",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "empieza",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "a",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "nadar",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "alimento",
                  "rawType": "int32",
                  "type": "integer"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "c7c4afdb-78eb-4d7c-bba7-ea27726f3367",
              "rows": [
                [
                  "d0",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d2",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d3",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "1",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d4",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "d5",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>pÃ¡jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    El  pÃ¡jaro  come  semillas  se  despierta  y  canta  pez  nada  en  el  \\\n",
              "d0   1       1     1         1   0          0  0      0    0     0   0   0   \n",
              "d1   1       1     0         0   1          1  1      1    0     0   0   0   \n",
              "d2   1       1     1         1   0          0  1      1    0     0   0   0   \n",
              "d3   1       0     1         0   0          0  1      0    1     1   1   1   \n",
              "d4   1       0     0         0   0          0  0      0    1     0   0   0   \n",
              "d5   1       0     1         0   0          0  0      0    1     0   0   0   \n",
              "\n",
              "    agua  empieza  a  nadar  alimento  \n",
              "d0     0        0  0      0         0  \n",
              "d1     0        0  0      0         0  \n",
              "d2     0        0  0      0         0  \n",
              "d3     1        0  0      0         0  \n",
              "d4     0        1  1      1         0  \n",
              "d5     0        0  0      0         1  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(corpus)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEA2Ic2sLlh"
      },
      "source": [
        "SoluciÃ³n esperada:\n",
        "\n",
        "|    |   El |   pÃ¡jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMv3UZdRhgqT"
      },
      "source": [
        "## P4. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxW5CZjhoE9"
      },
      "source": [
        "### 4.a TF (0.25 puntos)\n",
        "\n",
        "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la mÃ¡xima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
        "$i$ corresponde al Ã­ndice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca mÃ¡s veces en ese vector.\n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
        "\n",
        "Implemente la funciÃ³n `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qQhnJuuShmR5"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    return dataset_bow.div(dataset_bow.max(axis='columns'), axis='index')\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "urDKFQVu2p3V",
        "outputId": "4e333698-99e7-4ae9-8928-7d13f45bab32"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "El",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pÃ¡jaro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "come",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "semillas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "se",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "despierta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "y",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "canta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pez",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nada",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "en",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "el",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "agua",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "empieza",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "a",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nadar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "alimento",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "675e2a09-6753-4021-9531-3a32d0bf3aa0",
              "rows": [
                [
                  "d0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d1",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d2",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d3",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d4",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0"
                ],
                [
                  "d5",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>pÃ¡jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     El  pÃ¡jaro  come  semillas   se  despierta    y  canta  pez  nada   en  \\\n",
              "d0  1.0     1.0   1.0       1.0  0.0        0.0  0.0    0.0  0.0   0.0  0.0   \n",
              "d1  1.0     1.0   0.0       0.0  1.0        1.0  1.0    1.0  0.0   0.0  0.0   \n",
              "d2  1.0     1.0   1.0       1.0  0.0        0.0  1.0    1.0  0.0   0.0  0.0   \n",
              "d3  1.0     0.0   1.0       0.0  0.0        0.0  1.0    0.0  1.0   1.0  1.0   \n",
              "d4  1.0     0.0   0.0       0.0  0.0        0.0  0.0    0.0  1.0   0.0  0.0   \n",
              "d5  1.0     0.0   1.0       0.0  0.0        0.0  0.0    0.0  1.0   0.0  0.0   \n",
              "\n",
              "     el  agua  empieza    a  nadar  alimento  \n",
              "d0  0.0   0.0      0.0  0.0    0.0       0.0  \n",
              "d1  0.0   0.0      0.0  0.0    0.0       0.0  \n",
              "d2  0.0   0.0      0.0  0.0    0.0       0.0  \n",
              "d3  1.0   1.0      0.0  0.0    0.0       0.0  \n",
              "d4  0.0   0.0      1.0  1.0    1.0       0.0  \n",
              "d5  0.0   0.0      0.0  0.0    0.0       1.0  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo3ZjwVtZlq"
      },
      "source": [
        "SoluciÃ³n esperada:\n",
        "\n",
        "|    |   El |   pÃ¡jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh2bFyHFhpbM"
      },
      "source": [
        "### 4.b IDF (0.5 puntos)\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. Ã‰sta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el cÃ¡lculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ nÃºmero de documentos y $n_i = $ nÃºmero de documentos que contienen la palabra $t_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tGLjlSY02usu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qoU4AIrm2sDT"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    N = dataset_bow.shape[0]\n",
        "    doc_counts = (dataset_bow > 0).sum(axis=0)\n",
        "    idf = np.log10(N / doc_counts)\n",
        "    return idf.to_dict()\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXPErPdw2uQx",
        "outputId": "82946019-d734-4bd3-b0ad-49e56178a6d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'El': 0.0,\n",
              " 'pÃ¡jaro': 0.3010299956639812,\n",
              " 'come': 0.17609125905568124,\n",
              " 'semillas': 0.47712125471966244,\n",
              " 'se': 0.7781512503836436,\n",
              " 'despierta': 0.7781512503836436,\n",
              " 'y': 0.3010299956639812,\n",
              " 'canta': 0.47712125471966244,\n",
              " 'pez': 0.3010299956639812,\n",
              " 'nada': 0.7781512503836436,\n",
              " 'en': 0.7781512503836436,\n",
              " 'el': 0.7781512503836436,\n",
              " 'agua': 0.7781512503836436,\n",
              " 'empieza': 0.7781512503836436,\n",
              " 'a': 0.7781512503836436,\n",
              " 'nadar': 0.7781512503836436,\n",
              " 'alimento': 0.7781512503836436}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmp5lXdquAD1"
      },
      "source": [
        "SoluciÃ³n esperada:\n",
        "```\n",
        "{'El': 0.0,\n",
        " 'pÃ¡jaro': 0.3010299956639812,\n",
        " 'despierta': 0.7781512503836436,\n",
        " 'el': 0.7781512503836436,\n",
        " 'come': 0.17609125905568124,\n",
        " 'a': 0.7781512503836436,\n",
        " 'nadar': 0.7781512503836436,\n",
        " 'se': 0.7781512503836436,\n",
        " 'en': 0.7781512503836436,\n",
        " 'y': 0.3010299956639812,\n",
        " 'alimento': 0.7781512503836436,\n",
        " 'semillas': 0.47712125471966244,\n",
        " 'pez': 0.3010299956639812,\n",
        " 'empieza': 0.7781512503836436,\n",
        " 'canta': 0.47712125471966244,\n",
        " 'agua': 0.7781512503836436,\n",
        " 'nada': 0.7781512503836436}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-_vwiV20XL"
      },
      "source": [
        "### 4.c TF-IDF (0.25 puntos)\n",
        "Programe la funciÃ³n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "004IuUyt23_6"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    return tf * idf\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "KXjP0S3626dw",
        "outputId": "05c27756-026b-46da-a5f2-88d30a52ae08"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "El",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pÃ¡jaro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "come",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "semillas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "se",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "despierta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "y",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "canta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pez",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nada",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "en",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "el",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "agua",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "empieza",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "a",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nadar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "alimento",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "1d3eb3a4-e355-454d-9c2d-71bcc9b60060",
              "rows": [
                [
                  "d0",
                  "0.0",
                  "0.3010299956639812",
                  "0.17609125905568124",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d1",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.0",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.3010299956639812",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d2",
                  "0.0",
                  "0.3010299956639812",
                  "0.17609125905568124",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d3",
                  "0.0",
                  "0.0",
                  "0.17609125905568124",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.3010299956639812",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d4",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.0"
                ],
                [
                  "d5",
                  "0.0",
                  "0.0",
                  "0.17609125905568124",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.7781512503836436"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>pÃ¡jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     El   pÃ¡jaro      come  semillas        se  despierta        y     canta  \\\n",
              "d0  0.0  0.30103  0.176091  0.477121  0.000000   0.000000  0.00000  0.000000   \n",
              "d1  0.0  0.30103  0.000000  0.000000  0.778151   0.778151  0.30103  0.477121   \n",
              "d2  0.0  0.30103  0.176091  0.477121  0.000000   0.000000  0.30103  0.477121   \n",
              "d3  0.0  0.00000  0.176091  0.000000  0.000000   0.000000  0.30103  0.000000   \n",
              "d4  0.0  0.00000  0.000000  0.000000  0.000000   0.000000  0.00000  0.000000   \n",
              "d5  0.0  0.00000  0.176091  0.000000  0.000000   0.000000  0.00000  0.000000   \n",
              "\n",
              "        pez      nada        en        el      agua   empieza         a  \\\n",
              "d0  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "d1  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "d2  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "d3  0.30103  0.778151  0.778151  0.778151  0.778151  0.000000  0.000000   \n",
              "d4  0.30103  0.000000  0.000000  0.000000  0.000000  0.778151  0.778151   \n",
              "d5  0.30103  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "       nadar  alimento  \n",
              "d0  0.000000  0.000000  \n",
              "d1  0.000000  0.000000  \n",
              "d2  0.000000  0.000000  \n",
              "d3  0.000000  0.000000  \n",
              "d4  0.778151  0.000000  \n",
              "d5  0.000000  0.778151  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTa32IsuLWl"
      },
      "source": [
        "SoluciÃ³n esperada:\n",
        "\n",
        "|    |   El |   pÃ¡jaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
        "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
        "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
        "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
        "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
        "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8sQEjVshjQ7"
      },
      "source": [
        "## P5. Cosine-similarity (0.25 puntos)\n",
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante serÃ¡ una matriz simÃ©trica.\n",
        "\n",
        "Implemente la funciÃ³n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cuÃ¡les son los dos documentos mÃ¡s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_68mo-BLhmuV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    ### AquÃ­ inicia tu cÃ³digo ###\n",
        "    return np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "    ### AquÃ­ termina tu cÃ³digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z-23CN2_lU",
        "outputId": "c15b23a9-8e49-4570-a646-318527549199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El pÃ¡jaro come semillas\n",
            "> Mas similar: El pÃ¡jaro canta y come semillas\n",
            "> Similitud: 0.7233435041520414 \n",
            "\n",
            "El pÃ¡jaro se despierta y canta\n",
            "> Mas similar: El pÃ¡jaro canta y come semillas\n",
            "> Similitud: 0.3932010182312894 \n",
            "\n",
            "El pÃ¡jaro canta y come semillas\n",
            "> Mas similar: El pÃ¡jaro come semillas\n",
            "> Similitud: 0.7233435041520414 \n",
            "\n",
            "El pez come y nada en el agua\n",
            "> Mas similar: El pÃ¡jaro canta y come semillas\n",
            "> Similitud: 0.09171890791406168 \n",
            "\n",
            "El pez empieza a nadar\n",
            "> Mas similar: El pez come alimento\n",
            "> Similitud: 0.07695078406752713 \n",
            "\n",
            "El pez come alimento\n",
            "> Mas similar: El pez come y nada en el agua\n",
            "> Similitud: 0.08787900372173231 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n",
        "\n",
        "for i in range(6):\n",
        "  mask = [k != i for k in range(6)]\n",
        "  j = np.argmax(similarity_matrix[i][mask])\n",
        "\n",
        "  print(corpus[i])\n",
        "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
        "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oH4JHXulGQ"
      },
      "source": [
        "SoluciÃ³n esperada:\n",
        "```\n",
        "El pÃ¡jaro come semillas\n",
        "> Mas similar: El pÃ¡jaro canta y come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pÃ¡jaro se despierta y canta\n",
        "> Mas similar: El pÃ¡jaro canta y come semillas\n",
        "> Similitud: 0.39320101823128945\n",
        "\n",
        "El pÃ¡jaro canta y come semillas\n",
        "> Mas similar: El pÃ¡jaro come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pez come y nada en el agua\n",
        "> Mas similar: El pÃ¡jaro canta y come semillas\n",
        "> Similitud: 0.09171890791406168\n",
        "\n",
        "El pez empieza a nadar\n",
        "> Mas similar: El pez come alimento\n",
        "> Similitud: 0.07695078406752713\n",
        "\n",
        "El pez come alimento\n",
        "> Mas similar: El pez come y nada en el agua\n",
        "> Similitud: 0.0878790037217323\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDZln45jfjMf"
      },
      "source": [
        "## P6 N-gramas (0.75 punto)\n",
        "\n",
        "En esta secciÃ³n debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7duKoBvlSgg"
      },
      "source": [
        "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
        "\n",
        "En esta subsecciÃ³n debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDVurFfl3eZ",
        "outputId": "bf1f0dda-28c8-4ed3-d68d-5d27d497c65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"Â¡Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[RefrÃ¡\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto[:50])\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"OcurriÃ³ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYCw0AqOmlzD"
      },
      "source": [
        "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "C88f9aVil9d_"
      },
      "outputs": [],
      "source": [
        "def get_sentences(texto):\n",
        "  ## Implementar aquÃ­\n",
        "  return [x for x in texto.split('\\n') if len(x.split(' '))>0 and len(x.split(' ')[0])>0]\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZ8EhgHmR2c",
        "outputId": "e503f1a5-8c57-4fb6-8fca-5fccedaa18e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[Letra de \"Â¡Oh, Algoritmo!\" ft. Nora Erez]',\n",
              " '[RefrÃ¡n: Jorge Drexler]',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime quÃ© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'SÃ© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 1: Nora Erez]',\n",
              " \"Wait, what's that money that you spent?\",\n",
              " \"What's that sitting on your plate?\",\n",
              " \"Do you want what you've been fed?\",\n",
              " 'Are you the fish or bait?',\n",
              " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
              " 'Rather not pay the bail',\n",
              " 'To dangerous people with blood on their faces',\n",
              " \"So I'm sharing a cell with the masses\",\n",
              " 'The underground always strive for the main',\n",
              " \"Streaming like Grande's big-ass ring\",\n",
              " \"Screaming: I'll write you out my will\",\n",
              " 'Conscious is free, but not the will',\n",
              " 'Conscious is free, but not the will',\n",
              " 'You might also like',\n",
              " 'Amor al Arte',\n",
              " 'Jorge Drexler',\n",
              " 'Tinta y Tiempo',\n",
              " 'Jorge Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge Drexler',\n",
              " '[Pre-Estribillo: Nora Erez]',\n",
              " 'So if you want me to want what I believe that I want',\n",
              " 'Can I choose to quit?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime quÃ© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'SÃ© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 2: Jorge Drexler]',\n",
              " 'Por ejemplo, esta canciÃ³n',\n",
              " 'Â¿QuÃ© algoritmo la pariÃ³?',\n",
              " 'Me pregunto si fui yo',\n",
              " 'Â¿La elegiste o te eligiÃ³?',\n",
              " '[Verso 3: Jorge Drexler]',\n",
              " 'Dios era la letra chica al final del papel',\n",
              " 'Ya no contamos con Ã‰l',\n",
              " 'Fin de la Luna de miel',\n",
              " 'Y el libre albedrÃ­o es un cauce vacÃ­o',\n",
              " 'Un barco que no tiene rÃ­o',\n",
              " 'Ni timonel',\n",
              " '[Verso 4: Jorge Drexler]',\n",
              " 'Todos aplauden, tÃº tambiÃ©n',\n",
              " 'Pero no queda claro quiÃ©n',\n",
              " 'Tiene del mango a la sartÃ©n',\n",
              " 'Del sacrificio',\n",
              " 'Piel o silicio',\n",
              " 'Y el precipicio',\n",
              " 'Dice: Ven, ven, ven',\n",
              " '[RefrÃ¡n: Jorge Drexler]',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime quÃ© debo cantar)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(SÃ© que lo sabes mejor)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime quÃ© debo cantar)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(SÃ© que lo sabes mejor)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " 'Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oraciones_limpias = get_sentences(texto)\n",
        "oraciones_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBzcR6Ym0Us"
      },
      "source": [
        "DeberÃ­a obtener en total 87 oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pDN1vGEmwRQ",
        "outputId": "7ecc8706-1e5b-4809-cb61-08c860d70458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(oraciones_limpias) == 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dq8omm7cD"
      },
      "source": [
        "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHoR_-inEK1",
        "outputId": "de90d839-0d2e-410f-ab8a-eca02a3882f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 18)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = int(len(oraciones_limpias) * 0.8)\n",
        "train_corpus = oraciones_limpias[:split]\n",
        "test_corpus = oraciones_limpias[split:]\n",
        "\n",
        "len(train_corpus), len(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csdw0qNsmjTF"
      },
      "source": [
        "### 6.b EstimaciÃ³n de N-gramas (0.5 puntos)\n",
        "\n",
        "Defina una funciÃ³n que reciba una lista de oraciones de un corpus y un N que indique el tamaÃ±o de los N-gramas. La funciÃ³n debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe aÃ±adir un token especial al inicio o final de cada oraciÃ³n segÃºn corresponda (ver clases del curso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB2_1y1etIBF",
        "outputId": "0b5c7b06-bc8f-47c9-e447-b34495407154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\rodri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Lbrl3WVnmRzj"
      },
      "outputs": [],
      "source": [
        "def n_grams(corpus, n=3):\n",
        "  ## Implementar aquÃ­\n",
        "\n",
        "  assert n in [1,2,3]\n",
        "\n",
        "  token_lists = [\n",
        "      word_tokenize(f\"BOS {sent.strip()} EOS\") if n>1\n",
        "      else word_tokenize(sent)\n",
        "      for sent in corpus\n",
        "  ]\n",
        "\n",
        "  all_ngrams = [\n",
        "      tuple(tokens[i : i+n])\n",
        "      for tokens in token_lists\n",
        "      for i in range(len(tokens) - n + 1)\n",
        "  ]\n",
        "\n",
        "  freqs = Counter(all_ngrams) if n>1 else Counter(all_ngrams + [])\n",
        "\n",
        "  return dict(freqs)\n",
        "\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAoYncsp3C7u",
        "outputId": "cf08490d-e7d6-45c8-9027-39d6436a46f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('[',): 10,\n",
              " ('Letra',): 1,\n",
              " ('de',): 3,\n",
              " ('``',): 1,\n",
              " ('Â¡Oh',): 1,\n",
              " (',',): 11,\n",
              " ('Algoritmo',): 1,\n",
              " ('!',): 1,\n",
              " (\"''\",): 1,\n",
              " ('ft.',): 1,\n",
              " ('Nora',): 3,\n",
              " ('Erez',): 3,\n",
              " (']',): 10,\n",
              " ('RefrÃ¡n',): 2,\n",
              " (':',): 11,\n",
              " ('Jorge',): 10,\n",
              " ('Drexler',): 10,\n",
              " ('Â¿QuiÃ©n',): 11,\n",
              " ('quiere',): 11,\n",
              " ('que',): 38,\n",
              " ('yo',): 14,\n",
              " ('quiera',): 11,\n",
              " ('lo',): 13,\n",
              " ('creo',): 11,\n",
              " ('quiero',): 11,\n",
              " ('?',): 18,\n",
              " ('Estribillo',): 2,\n",
              " ('Dime',): 3,\n",
              " ('quÃ©',): 3,\n",
              " ('debo',): 3,\n",
              " ('cantar',): 3,\n",
              " ('Oh',): 2,\n",
              " ('algoritmo',): 3,\n",
              " ('SÃ©',): 2,\n",
              " ('sabes',): 2,\n",
              " ('mejor',): 2,\n",
              " ('Incluso',): 2,\n",
              " ('mismo',): 2,\n",
              " ('Verso',): 4,\n",
              " ('1',): 1,\n",
              " ('Wait',): 1,\n",
              " ('what',): 3,\n",
              " (\"'s\",): 3,\n",
              " ('that',): 4,\n",
              " ('money',): 1,\n",
              " ('you',): 6,\n",
              " ('spent',): 1,\n",
              " ('What',): 1,\n",
              " ('sitting',): 1,\n",
              " ('on',): 3,\n",
              " ('your',): 1,\n",
              " ('plate',): 1,\n",
              " ('Do',): 1,\n",
              " ('want',): 4,\n",
              " (\"'ve\",): 1,\n",
              " ('been',): 1,\n",
              " ('fed',): 1,\n",
              " ('Are',): 1,\n",
              " ('the',): 8,\n",
              " ('fish',): 1,\n",
              " ('or',): 1,\n",
              " ('bait',): 1,\n",
              " ('Mmm',): 1,\n",
              " ('I',): 7,\n",
              " (\"'m\",): 2,\n",
              " ('top',): 1,\n",
              " ('of',): 1,\n",
              " ('roof',): 1,\n",
              " ('and',): 1,\n",
              " ('feel',): 1,\n",
              " ('like',): 3,\n",
              " ('a',): 3,\n",
              " ('jail',): 1,\n",
              " ('Rather',): 1,\n",
              " ('not',): 3,\n",
              " ('pay',): 1,\n",
              " ('bail',): 1,\n",
              " ('To',): 1,\n",
              " ('dangerous',): 1,\n",
              " ('people',): 1,\n",
              " ('with',): 2,\n",
              " ('blood',): 1,\n",
              " ('their',): 1,\n",
              " ('faces',): 1,\n",
              " ('So',): 2,\n",
              " ('sharing',): 1,\n",
              " ('cell',): 1,\n",
              " ('masses',): 1,\n",
              " ('The',): 1,\n",
              " ('underground',): 1,\n",
              " ('always',): 1,\n",
              " ('strive',): 1,\n",
              " ('for',): 1,\n",
              " ('main',): 1,\n",
              " ('Streaming',): 1,\n",
              " ('Grande',): 1,\n",
              " ('big-ass',): 1,\n",
              " ('ring',): 1,\n",
              " ('Screaming',): 1,\n",
              " (\"'ll\",): 1,\n",
              " ('write',): 1,\n",
              " ('out',): 1,\n",
              " ('my',): 1,\n",
              " ('will',): 3,\n",
              " ('Conscious',): 2,\n",
              " ('is',): 2,\n",
              " ('free',): 2,\n",
              " ('but',): 2,\n",
              " ('You',): 1,\n",
              " ('might',): 1,\n",
              " ('also',): 1,\n",
              " ('Amor',): 1,\n",
              " ('al',): 2,\n",
              " ('Arte',): 1,\n",
              " ('Tinta',): 1,\n",
              " ('y',): 1,\n",
              " ('Tiempo',): 1,\n",
              " ('Asilo',): 1,\n",
              " ('Pre-Estribillo',): 1,\n",
              " ('if',): 1,\n",
              " ('me',): 1,\n",
              " ('to',): 2,\n",
              " ('believe',): 1,\n",
              " ('Can',): 1,\n",
              " ('choose',): 1,\n",
              " ('quit',): 1,\n",
              " ('2',): 1,\n",
              " ('Por',): 1,\n",
              " ('ejemplo',): 1,\n",
              " ('esta',): 1,\n",
              " ('canciÃ³n',): 1,\n",
              " ('Â¿QuÃ©',): 1,\n",
              " ('la',): 4,\n",
              " ('pariÃ³',): 1,\n",
              " ('Me',): 1,\n",
              " ('pregunto',): 1,\n",
              " ('si',): 1,\n",
              " ('fui',): 1,\n",
              " ('Â¿La',): 1,\n",
              " ('elegiste',): 1,\n",
              " ('o',): 2,\n",
              " ('te',): 1,\n",
              " ('eligiÃ³',): 1,\n",
              " ('3',): 1,\n",
              " ('Dios',): 1,\n",
              " ('era',): 1,\n",
              " ('letra',): 1,\n",
              " ('chica',): 1,\n",
              " ('final',): 1,\n",
              " ('del',): 2,\n",
              " ('papel',): 1,\n",
              " ('Ya',): 1,\n",
              " ('no',): 3,\n",
              " ('contamos',): 1,\n",
              " ('con',): 1,\n",
              " ('Ã‰l',): 1,\n",
              " ('Fin',): 1,\n",
              " ('Luna',): 1,\n",
              " ('miel',): 1,\n",
              " ('Y',): 2,\n",
              " ('el',): 2,\n",
              " ('libre',): 1,\n",
              " ('albedrÃ­o',): 1,\n",
              " ('es',): 1,\n",
              " ('un',): 1,\n",
              " ('cauce',): 1,\n",
              " ('vacÃ­o',): 1,\n",
              " ('Un',): 1,\n",
              " ('barco',): 1,\n",
              " ('tiene',): 1,\n",
              " ('rÃ­o',): 1,\n",
              " ('Ni',): 1,\n",
              " ('timonel',): 1,\n",
              " ('4',): 1,\n",
              " ('Todos',): 1,\n",
              " ('aplauden',): 1,\n",
              " ('tÃº',): 1,\n",
              " ('tambiÃ©n',): 1,\n",
              " ('Pero',): 1,\n",
              " ('queda',): 1,\n",
              " ('claro',): 1,\n",
              " ('quiÃ©n',): 1,\n",
              " ('Tiene',): 1,\n",
              " ('mango',): 1,\n",
              " ('sartÃ©n',): 1,\n",
              " ('Del',): 1,\n",
              " ('sacrificio',): 1,\n",
              " ('Piel',): 1,\n",
              " ('silicio',): 1,\n",
              " ('precipicio',): 1,\n",
              " ('Dice',): 1,\n",
              " ('Ven',): 1,\n",
              " ('ven',): 2,\n",
              " ('(',): 1,\n",
              " (')',): 1}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8XDEuRF3Grx",
        "outputId": "80e595f0-9ae9-4bab-d340-bcdc5987afdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('BOS', '['): 10,\n",
              " ('[', 'Letra'): 1,\n",
              " ('Letra', 'de'): 1,\n",
              " ('de', '``'): 1,\n",
              " ('``', 'Â¡Oh'): 1,\n",
              " ('Â¡Oh', ','): 1,\n",
              " (',', 'Algoritmo'): 1,\n",
              " ('Algoritmo', '!'): 1,\n",
              " ('!', \"''\"): 1,\n",
              " (\"''\", 'ft.'): 1,\n",
              " ('ft.', 'Nora'): 1,\n",
              " ('Nora', 'Erez'): 3,\n",
              " ('Erez', ']'): 3,\n",
              " (']', 'EOS'): 10,\n",
              " ('[', 'RefrÃ¡n'): 2,\n",
              " ('RefrÃ¡n', ':'): 2,\n",
              " (':', 'Jorge'): 7,\n",
              " ('Jorge', 'Drexler'): 10,\n",
              " ('Drexler', ']'): 7,\n",
              " ('BOS', 'Â¿QuiÃ©n'): 11,\n",
              " ('Â¿QuiÃ©n', 'quiere'): 11,\n",
              " ('quiere', 'que'): 11,\n",
              " ('que', 'yo'): 13,\n",
              " ('yo', 'quiera'): 11,\n",
              " ('quiera', 'lo'): 11,\n",
              " ('lo', 'que'): 11,\n",
              " ('que', 'creo'): 11,\n",
              " ('creo', 'que'): 11,\n",
              " ('que', 'quiero'): 11,\n",
              " ('quiero', '?'): 11,\n",
              " ('?', 'EOS'): 18,\n",
              " ('[', 'Estribillo'): 2,\n",
              " ('Estribillo', ':'): 2,\n",
              " ('BOS', 'Dime'): 2,\n",
              " ('Dime', 'quÃ©'): 3,\n",
              " ('quÃ©', 'debo'): 3,\n",
              " ('debo', 'cantar'): 3,\n",
              " ('cantar', 'EOS'): 2,\n",
              " ('BOS', 'Oh'): 2,\n",
              " ('Oh', ','): 2,\n",
              " (',', 'algoritmo'): 2,\n",
              " ('algoritmo', 'EOS'): 2,\n",
              " ('BOS', 'SÃ©'): 2,\n",
              " ('SÃ©', 'que'): 2,\n",
              " ('que', 'lo'): 2,\n",
              " ('lo', 'sabes'): 2,\n",
              " ('sabes', 'mejor'): 2,\n",
              " ('mejor', 'EOS'): 2,\n",
              " ('BOS', 'Incluso'): 2,\n",
              " ('Incluso', 'que'): 2,\n",
              " ('yo', 'mismo'): 2,\n",
              " ('mismo', 'EOS'): 2,\n",
              " ('[', 'Verso'): 4,\n",
              " ('Verso', '1'): 1,\n",
              " ('1', ':'): 1,\n",
              " (':', 'Nora'): 2,\n",
              " ('BOS', 'Wait'): 1,\n",
              " ('Wait', ','): 1,\n",
              " (',', 'what'): 1,\n",
              " ('what', \"'s\"): 1,\n",
              " (\"'s\", 'that'): 2,\n",
              " ('that', 'money'): 1,\n",
              " ('money', 'that'): 1,\n",
              " ('that', 'you'): 1,\n",
              " ('you', 'spent'): 1,\n",
              " ('spent', '?'): 1,\n",
              " ('BOS', 'What'): 1,\n",
              " ('What', \"'s\"): 1,\n",
              " ('that', 'sitting'): 1,\n",
              " ('sitting', 'on'): 1,\n",
              " ('on', 'your'): 1,\n",
              " ('your', 'plate'): 1,\n",
              " ('plate', '?'): 1,\n",
              " ('BOS', 'Do'): 1,\n",
              " ('Do', 'you'): 1,\n",
              " ('you', 'want'): 2,\n",
              " ('want', 'what'): 2,\n",
              " ('what', 'you'): 1,\n",
              " ('you', \"'ve\"): 1,\n",
              " (\"'ve\", 'been'): 1,\n",
              " ('been', 'fed'): 1,\n",
              " ('fed', '?'): 1,\n",
              " ('BOS', 'Are'): 1,\n",
              " ('Are', 'you'): 1,\n",
              " ('you', 'the'): 1,\n",
              " ('the', 'fish'): 1,\n",
              " ('fish', 'or'): 1,\n",
              " ('or', 'bait'): 1,\n",
              " ('bait', '?'): 1,\n",
              " ('BOS', 'Mmm'): 1,\n",
              " ('Mmm', ','): 1,\n",
              " (',', 'I'): 1,\n",
              " ('I', \"'m\"): 2,\n",
              " (\"'m\", 'on'): 1,\n",
              " ('on', 'the'): 1,\n",
              " ('the', 'top'): 1,\n",
              " ('top', 'of'): 1,\n",
              " ('of', 'the'): 1,\n",
              " ('the', 'roof'): 1,\n",
              " ('roof', 'and'): 1,\n",
              " ('and', 'I'): 1,\n",
              " ('I', 'feel'): 1,\n",
              " ('feel', 'like'): 1,\n",
              " ('like', 'a'): 1,\n",
              " ('a', 'jail'): 1,\n",
              " ('jail', 'EOS'): 1,\n",
              " ('BOS', 'Rather'): 1,\n",
              " ('Rather', 'not'): 1,\n",
              " ('not', 'pay'): 1,\n",
              " ('pay', 'the'): 1,\n",
              " ('the', 'bail'): 1,\n",
              " ('bail', 'EOS'): 1,\n",
              " ('BOS', 'To'): 1,\n",
              " ('To', 'dangerous'): 1,\n",
              " ('dangerous', 'people'): 1,\n",
              " ('people', 'with'): 1,\n",
              " ('with', 'blood'): 1,\n",
              " ('blood', 'on'): 1,\n",
              " ('on', 'their'): 1,\n",
              " ('their', 'faces'): 1,\n",
              " ('faces', 'EOS'): 1,\n",
              " ('BOS', 'So'): 2,\n",
              " ('So', 'I'): 1,\n",
              " (\"'m\", 'sharing'): 1,\n",
              " ('sharing', 'a'): 1,\n",
              " ('a', 'cell'): 1,\n",
              " ('cell', 'with'): 1,\n",
              " ('with', 'the'): 1,\n",
              " ('the', 'masses'): 1,\n",
              " ('masses', 'EOS'): 1,\n",
              " ('BOS', 'The'): 1,\n",
              " ('The', 'underground'): 1,\n",
              " ('underground', 'always'): 1,\n",
              " ('always', 'strive'): 1,\n",
              " ('strive', 'for'): 1,\n",
              " ('for', 'the'): 1,\n",
              " ('the', 'main'): 1,\n",
              " ('main', 'EOS'): 1,\n",
              " ('BOS', 'Streaming'): 1,\n",
              " ('Streaming', 'like'): 1,\n",
              " ('like', 'Grande'): 1,\n",
              " ('Grande', \"'s\"): 1,\n",
              " (\"'s\", 'big-ass'): 1,\n",
              " ('big-ass', 'ring'): 1,\n",
              " ('ring', 'EOS'): 1,\n",
              " ('BOS', 'Screaming'): 1,\n",
              " ('Screaming', ':'): 1,\n",
              " (':', 'I'): 1,\n",
              " ('I', \"'ll\"): 1,\n",
              " (\"'ll\", 'write'): 1,\n",
              " ('write', 'you'): 1,\n",
              " ('you', 'out'): 1,\n",
              " ('out', 'my'): 1,\n",
              " ('my', 'will'): 1,\n",
              " ('will', 'EOS'): 3,\n",
              " ('BOS', 'Conscious'): 2,\n",
              " ('Conscious', 'is'): 2,\n",
              " ('is', 'free'): 2,\n",
              " ('free', ','): 2,\n",
              " (',', 'but'): 2,\n",
              " ('but', 'not'): 2,\n",
              " ('not', 'the'): 2,\n",
              " ('the', 'will'): 2,\n",
              " ('BOS', 'You'): 1,\n",
              " ('You', 'might'): 1,\n",
              " ('might', 'also'): 1,\n",
              " ('also', 'like'): 1,\n",
              " ('like', 'EOS'): 1,\n",
              " ('BOS', 'Amor'): 1,\n",
              " ('Amor', 'al'): 1,\n",
              " ('al', 'Arte'): 1,\n",
              " ('Arte', 'EOS'): 1,\n",
              " ('BOS', 'Jorge'): 3,\n",
              " ('Drexler', 'EOS'): 3,\n",
              " ('BOS', 'Tinta'): 1,\n",
              " ('Tinta', 'y'): 1,\n",
              " ('y', 'Tiempo'): 1,\n",
              " ('Tiempo', 'EOS'): 1,\n",
              " ('BOS', 'Asilo'): 1,\n",
              " ('Asilo', 'EOS'): 1,\n",
              " ('[', 'Pre-Estribillo'): 1,\n",
              " ('Pre-Estribillo', ':'): 1,\n",
              " ('So', 'if'): 1,\n",
              " ('if', 'you'): 1,\n",
              " ('want', 'me'): 1,\n",
              " ('me', 'to'): 1,\n",
              " ('to', 'want'): 1,\n",
              " ('what', 'I'): 1,\n",
              " ('I', 'believe'): 1,\n",
              " ('believe', 'that'): 1,\n",
              " ('that', 'I'): 1,\n",
              " ('I', 'want'): 1,\n",
              " ('want', 'EOS'): 1,\n",
              " ('BOS', 'Can'): 1,\n",
              " ('Can', 'I'): 1,\n",
              " ('I', 'choose'): 1,\n",
              " ('choose', 'to'): 1,\n",
              " ('to', 'quit'): 1,\n",
              " ('quit', '?'): 1,\n",
              " ('Verso', '2'): 1,\n",
              " ('2', ':'): 1,\n",
              " ('BOS', 'Por'): 1,\n",
              " ('Por', 'ejemplo'): 1,\n",
              " ('ejemplo', ','): 1,\n",
              " (',', 'esta'): 1,\n",
              " ('esta', 'canciÃ³n'): 1,\n",
              " ('canciÃ³n', 'EOS'): 1,\n",
              " ('BOS', 'Â¿QuÃ©'): 1,\n",
              " ('Â¿QuÃ©', 'algoritmo'): 1,\n",
              " ('algoritmo', 'la'): 1,\n",
              " ('la', 'pariÃ³'): 1,\n",
              " ('pariÃ³', '?'): 1,\n",
              " ('BOS', 'Me'): 1,\n",
              " ('Me', 'pregunto'): 1,\n",
              " ('pregunto', 'si'): 1,\n",
              " ('si', 'fui'): 1,\n",
              " ('fui', 'yo'): 1,\n",
              " ('yo', 'EOS'): 1,\n",
              " ('BOS', 'Â¿La'): 1,\n",
              " ('Â¿La', 'elegiste'): 1,\n",
              " ('elegiste', 'o'): 1,\n",
              " ('o', 'te'): 1,\n",
              " ('te', 'eligiÃ³'): 1,\n",
              " ('eligiÃ³', '?'): 1,\n",
              " ('Verso', '3'): 1,\n",
              " ('3', ':'): 1,\n",
              " ('BOS', 'Dios'): 1,\n",
              " ('Dios', 'era'): 1,\n",
              " ('era', 'la'): 1,\n",
              " ('la', 'letra'): 1,\n",
              " ('letra', 'chica'): 1,\n",
              " ('chica', 'al'): 1,\n",
              " ('al', 'final'): 1,\n",
              " ('final', 'del'): 1,\n",
              " ('del', 'papel'): 1,\n",
              " ('papel', 'EOS'): 1,\n",
              " ('BOS', 'Ya'): 1,\n",
              " ('Ya', 'no'): 1,\n",
              " ('no', 'contamos'): 1,\n",
              " ('contamos', 'con'): 1,\n",
              " ('con', 'Ã‰l'): 1,\n",
              " ('Ã‰l', 'EOS'): 1,\n",
              " ('BOS', 'Fin'): 1,\n",
              " ('Fin', 'de'): 1,\n",
              " ('de', 'la'): 1,\n",
              " ('la', 'Luna'): 1,\n",
              " ('Luna', 'de'): 1,\n",
              " ('de', 'miel'): 1,\n",
              " ('miel', 'EOS'): 1,\n",
              " ('BOS', 'Y'): 2,\n",
              " ('Y', 'el'): 2,\n",
              " ('el', 'libre'): 1,\n",
              " ('libre', 'albedrÃ­o'): 1,\n",
              " ('albedrÃ­o', 'es'): 1,\n",
              " ('es', 'un'): 1,\n",
              " ('un', 'cauce'): 1,\n",
              " ('cauce', 'vacÃ­o'): 1,\n",
              " ('vacÃ­o', 'EOS'): 1,\n",
              " ('BOS', 'Un'): 1,\n",
              " ('Un', 'barco'): 1,\n",
              " ('barco', 'que'): 1,\n",
              " ('que', 'no'): 1,\n",
              " ('no', 'tiene'): 1,\n",
              " ('tiene', 'rÃ­o'): 1,\n",
              " ('rÃ­o', 'EOS'): 1,\n",
              " ('BOS', 'Ni'): 1,\n",
              " ('Ni', 'timonel'): 1,\n",
              " ('timonel', 'EOS'): 1,\n",
              " ('Verso', '4'): 1,\n",
              " ('4', ':'): 1,\n",
              " ('BOS', 'Todos'): 1,\n",
              " ('Todos', 'aplauden'): 1,\n",
              " ('aplauden', ','): 1,\n",
              " (',', 'tÃº'): 1,\n",
              " ('tÃº', 'tambiÃ©n'): 1,\n",
              " ('tambiÃ©n', 'EOS'): 1,\n",
              " ('BOS', 'Pero'): 1,\n",
              " ('Pero', 'no'): 1,\n",
              " ('no', 'queda'): 1,\n",
              " ('queda', 'claro'): 1,\n",
              " ('claro', 'quiÃ©n'): 1,\n",
              " ('quiÃ©n', 'EOS'): 1,\n",
              " ('BOS', 'Tiene'): 1,\n",
              " ('Tiene', 'del'): 1,\n",
              " ('del', 'mango'): 1,\n",
              " ('mango', 'a'): 1,\n",
              " ('a', 'la'): 1,\n",
              " ('la', 'sartÃ©n'): 1,\n",
              " ('sartÃ©n', 'EOS'): 1,\n",
              " ('BOS', 'Del'): 1,\n",
              " ('Del', 'sacrificio'): 1,\n",
              " ('sacrificio', 'EOS'): 1,\n",
              " ('BOS', 'Piel'): 1,\n",
              " ('Piel', 'o'): 1,\n",
              " ('o', 'silicio'): 1,\n",
              " ('silicio', 'EOS'): 1,\n",
              " ('el', 'precipicio'): 1,\n",
              " ('precipicio', 'EOS'): 1,\n",
              " ('BOS', 'Dice'): 1,\n",
              " ('Dice', ':'): 1,\n",
              " (':', 'Ven'): 1,\n",
              " ('Ven', ','): 1,\n",
              " (',', 'ven'): 2,\n",
              " ('ven', ','): 1,\n",
              " ('ven', 'EOS'): 1,\n",
              " ('BOS', '('): 1,\n",
              " ('(', 'Dime'): 1,\n",
              " ('cantar', ')'): 1,\n",
              " (')', 'EOS'): 1}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCpbhiXp3Gpg",
        "outputId": "cab2df5b-cfad-482a-dfac-1dcf3ddb4942"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('BOS', '[', 'Letra'): 1,\n",
              " ('[', 'Letra', 'de'): 1,\n",
              " ('Letra', 'de', '``'): 1,\n",
              " ('de', '``', 'Â¡Oh'): 1,\n",
              " ('``', 'Â¡Oh', ','): 1,\n",
              " ('Â¡Oh', ',', 'Algoritmo'): 1,\n",
              " (',', 'Algoritmo', '!'): 1,\n",
              " ('Algoritmo', '!', \"''\"): 1,\n",
              " ('!', \"''\", 'ft.'): 1,\n",
              " (\"''\", 'ft.', 'Nora'): 1,\n",
              " ('ft.', 'Nora', 'Erez'): 1,\n",
              " ('Nora', 'Erez', ']'): 3,\n",
              " ('Erez', ']', 'EOS'): 3,\n",
              " ('BOS', '[', 'RefrÃ¡n'): 2,\n",
              " ('[', 'RefrÃ¡n', ':'): 2,\n",
              " ('RefrÃ¡n', ':', 'Jorge'): 2,\n",
              " (':', 'Jorge', 'Drexler'): 7,\n",
              " ('Jorge', 'Drexler', ']'): 7,\n",
              " ('Drexler', ']', 'EOS'): 7,\n",
              " ('BOS', 'Â¿QuiÃ©n', 'quiere'): 11,\n",
              " ('Â¿QuiÃ©n', 'quiere', 'que'): 11,\n",
              " ('quiere', 'que', 'yo'): 11,\n",
              " ('que', 'yo', 'quiera'): 11,\n",
              " ('yo', 'quiera', 'lo'): 11,\n",
              " ('quiera', 'lo', 'que'): 11,\n",
              " ('lo', 'que', 'creo'): 11,\n",
              " ('que', 'creo', 'que'): 11,\n",
              " ('creo', 'que', 'quiero'): 11,\n",
              " ('que', 'quiero', '?'): 11,\n",
              " ('quiero', '?', 'EOS'): 11,\n",
              " ('BOS', '[', 'Estribillo'): 2,\n",
              " ('[', 'Estribillo', ':'): 2,\n",
              " ('Estribillo', ':', 'Jorge'): 2,\n",
              " ('BOS', 'Dime', 'quÃ©'): 2,\n",
              " ('Dime', 'quÃ©', 'debo'): 3,\n",
              " ('quÃ©', 'debo', 'cantar'): 3,\n",
              " ('debo', 'cantar', 'EOS'): 2,\n",
              " ('BOS', 'Oh', ','): 2,\n",
              " ('Oh', ',', 'algoritmo'): 2,\n",
              " (',', 'algoritmo', 'EOS'): 2,\n",
              " ('BOS', 'SÃ©', 'que'): 2,\n",
              " ('SÃ©', 'que', 'lo'): 2,\n",
              " ('que', 'lo', 'sabes'): 2,\n",
              " ('lo', 'sabes', 'mejor'): 2,\n",
              " ('sabes', 'mejor', 'EOS'): 2,\n",
              " ('BOS', 'Incluso', 'que'): 2,\n",
              " ('Incluso', 'que', 'yo'): 2,\n",
              " ('que', 'yo', 'mismo'): 2,\n",
              " ('yo', 'mismo', 'EOS'): 2,\n",
              " ('BOS', '[', 'Verso'): 4,\n",
              " ('[', 'Verso', '1'): 1,\n",
              " ('Verso', '1', ':'): 1,\n",
              " ('1', ':', 'Nora'): 1,\n",
              " (':', 'Nora', 'Erez'): 2,\n",
              " ('BOS', 'Wait', ','): 1,\n",
              " ('Wait', ',', 'what'): 1,\n",
              " (',', 'what', \"'s\"): 1,\n",
              " ('what', \"'s\", 'that'): 1,\n",
              " (\"'s\", 'that', 'money'): 1,\n",
              " ('that', 'money', 'that'): 1,\n",
              " ('money', 'that', 'you'): 1,\n",
              " ('that', 'you', 'spent'): 1,\n",
              " ('you', 'spent', '?'): 1,\n",
              " ('spent', '?', 'EOS'): 1,\n",
              " ('BOS', 'What', \"'s\"): 1,\n",
              " ('What', \"'s\", 'that'): 1,\n",
              " (\"'s\", 'that', 'sitting'): 1,\n",
              " ('that', 'sitting', 'on'): 1,\n",
              " ('sitting', 'on', 'your'): 1,\n",
              " ('on', 'your', 'plate'): 1,\n",
              " ('your', 'plate', '?'): 1,\n",
              " ('plate', '?', 'EOS'): 1,\n",
              " ('BOS', 'Do', 'you'): 1,\n",
              " ('Do', 'you', 'want'): 1,\n",
              " ('you', 'want', 'what'): 1,\n",
              " ('want', 'what', 'you'): 1,\n",
              " ('what', 'you', \"'ve\"): 1,\n",
              " ('you', \"'ve\", 'been'): 1,\n",
              " (\"'ve\", 'been', 'fed'): 1,\n",
              " ('been', 'fed', '?'): 1,\n",
              " ('fed', '?', 'EOS'): 1,\n",
              " ('BOS', 'Are', 'you'): 1,\n",
              " ('Are', 'you', 'the'): 1,\n",
              " ('you', 'the', 'fish'): 1,\n",
              " ('the', 'fish', 'or'): 1,\n",
              " ('fish', 'or', 'bait'): 1,\n",
              " ('or', 'bait', '?'): 1,\n",
              " ('bait', '?', 'EOS'): 1,\n",
              " ('BOS', 'Mmm', ','): 1,\n",
              " ('Mmm', ',', 'I'): 1,\n",
              " (',', 'I', \"'m\"): 1,\n",
              " ('I', \"'m\", 'on'): 1,\n",
              " (\"'m\", 'on', 'the'): 1,\n",
              " ('on', 'the', 'top'): 1,\n",
              " ('the', 'top', 'of'): 1,\n",
              " ('top', 'of', 'the'): 1,\n",
              " ('of', 'the', 'roof'): 1,\n",
              " ('the', 'roof', 'and'): 1,\n",
              " ('roof', 'and', 'I'): 1,\n",
              " ('and', 'I', 'feel'): 1,\n",
              " ('I', 'feel', 'like'): 1,\n",
              " ('feel', 'like', 'a'): 1,\n",
              " ('like', 'a', 'jail'): 1,\n",
              " ('a', 'jail', 'EOS'): 1,\n",
              " ('BOS', 'Rather', 'not'): 1,\n",
              " ('Rather', 'not', 'pay'): 1,\n",
              " ('not', 'pay', 'the'): 1,\n",
              " ('pay', 'the', 'bail'): 1,\n",
              " ('the', 'bail', 'EOS'): 1,\n",
              " ('BOS', 'To', 'dangerous'): 1,\n",
              " ('To', 'dangerous', 'people'): 1,\n",
              " ('dangerous', 'people', 'with'): 1,\n",
              " ('people', 'with', 'blood'): 1,\n",
              " ('with', 'blood', 'on'): 1,\n",
              " ('blood', 'on', 'their'): 1,\n",
              " ('on', 'their', 'faces'): 1,\n",
              " ('their', 'faces', 'EOS'): 1,\n",
              " ('BOS', 'So', 'I'): 1,\n",
              " ('So', 'I', \"'m\"): 1,\n",
              " ('I', \"'m\", 'sharing'): 1,\n",
              " (\"'m\", 'sharing', 'a'): 1,\n",
              " ('sharing', 'a', 'cell'): 1,\n",
              " ('a', 'cell', 'with'): 1,\n",
              " ('cell', 'with', 'the'): 1,\n",
              " ('with', 'the', 'masses'): 1,\n",
              " ('the', 'masses', 'EOS'): 1,\n",
              " ('BOS', 'The', 'underground'): 1,\n",
              " ('The', 'underground', 'always'): 1,\n",
              " ('underground', 'always', 'strive'): 1,\n",
              " ('always', 'strive', 'for'): 1,\n",
              " ('strive', 'for', 'the'): 1,\n",
              " ('for', 'the', 'main'): 1,\n",
              " ('the', 'main', 'EOS'): 1,\n",
              " ('BOS', 'Streaming', 'like'): 1,\n",
              " ('Streaming', 'like', 'Grande'): 1,\n",
              " ('like', 'Grande', \"'s\"): 1,\n",
              " ('Grande', \"'s\", 'big-ass'): 1,\n",
              " (\"'s\", 'big-ass', 'ring'): 1,\n",
              " ('big-ass', 'ring', 'EOS'): 1,\n",
              " ('BOS', 'Screaming', ':'): 1,\n",
              " ('Screaming', ':', 'I'): 1,\n",
              " (':', 'I', \"'ll\"): 1,\n",
              " ('I', \"'ll\", 'write'): 1,\n",
              " (\"'ll\", 'write', 'you'): 1,\n",
              " ('write', 'you', 'out'): 1,\n",
              " ('you', 'out', 'my'): 1,\n",
              " ('out', 'my', 'will'): 1,\n",
              " ('my', 'will', 'EOS'): 1,\n",
              " ('BOS', 'Conscious', 'is'): 2,\n",
              " ('Conscious', 'is', 'free'): 2,\n",
              " ('is', 'free', ','): 2,\n",
              " ('free', ',', 'but'): 2,\n",
              " (',', 'but', 'not'): 2,\n",
              " ('but', 'not', 'the'): 2,\n",
              " ('not', 'the', 'will'): 2,\n",
              " ('the', 'will', 'EOS'): 2,\n",
              " ('BOS', 'You', 'might'): 1,\n",
              " ('You', 'might', 'also'): 1,\n",
              " ('might', 'also', 'like'): 1,\n",
              " ('also', 'like', 'EOS'): 1,\n",
              " ('BOS', 'Amor', 'al'): 1,\n",
              " ('Amor', 'al', 'Arte'): 1,\n",
              " ('al', 'Arte', 'EOS'): 1,\n",
              " ('BOS', 'Jorge', 'Drexler'): 3,\n",
              " ('Jorge', 'Drexler', 'EOS'): 3,\n",
              " ('BOS', 'Tinta', 'y'): 1,\n",
              " ('Tinta', 'y', 'Tiempo'): 1,\n",
              " ('y', 'Tiempo', 'EOS'): 1,\n",
              " ('BOS', 'Asilo', 'EOS'): 1,\n",
              " ('BOS', '[', 'Pre-Estribillo'): 1,\n",
              " ('[', 'Pre-Estribillo', ':'): 1,\n",
              " ('Pre-Estribillo', ':', 'Nora'): 1,\n",
              " ('BOS', 'So', 'if'): 1,\n",
              " ('So', 'if', 'you'): 1,\n",
              " ('if', 'you', 'want'): 1,\n",
              " ('you', 'want', 'me'): 1,\n",
              " ('want', 'me', 'to'): 1,\n",
              " ('me', 'to', 'want'): 1,\n",
              " ('to', 'want', 'what'): 1,\n",
              " ('want', 'what', 'I'): 1,\n",
              " ('what', 'I', 'believe'): 1,\n",
              " ('I', 'believe', 'that'): 1,\n",
              " ('believe', 'that', 'I'): 1,\n",
              " ('that', 'I', 'want'): 1,\n",
              " ('I', 'want', 'EOS'): 1,\n",
              " ('BOS', 'Can', 'I'): 1,\n",
              " ('Can', 'I', 'choose'): 1,\n",
              " ('I', 'choose', 'to'): 1,\n",
              " ('choose', 'to', 'quit'): 1,\n",
              " ('to', 'quit', '?'): 1,\n",
              " ('quit', '?', 'EOS'): 1,\n",
              " ('[', 'Verso', '2'): 1,\n",
              " ('Verso', '2', ':'): 1,\n",
              " ('2', ':', 'Jorge'): 1,\n",
              " ('BOS', 'Por', 'ejemplo'): 1,\n",
              " ('Por', 'ejemplo', ','): 1,\n",
              " ('ejemplo', ',', 'esta'): 1,\n",
              " (',', 'esta', 'canciÃ³n'): 1,\n",
              " ('esta', 'canciÃ³n', 'EOS'): 1,\n",
              " ('BOS', 'Â¿QuÃ©', 'algoritmo'): 1,\n",
              " ('Â¿QuÃ©', 'algoritmo', 'la'): 1,\n",
              " ('algoritmo', 'la', 'pariÃ³'): 1,\n",
              " ('la', 'pariÃ³', '?'): 1,\n",
              " ('pariÃ³', '?', 'EOS'): 1,\n",
              " ('BOS', 'Me', 'pregunto'): 1,\n",
              " ('Me', 'pregunto', 'si'): 1,\n",
              " ('pregunto', 'si', 'fui'): 1,\n",
              " ('si', 'fui', 'yo'): 1,\n",
              " ('fui', 'yo', 'EOS'): 1,\n",
              " ('BOS', 'Â¿La', 'elegiste'): 1,\n",
              " ('Â¿La', 'elegiste', 'o'): 1,\n",
              " ('elegiste', 'o', 'te'): 1,\n",
              " ('o', 'te', 'eligiÃ³'): 1,\n",
              " ('te', 'eligiÃ³', '?'): 1,\n",
              " ('eligiÃ³', '?', 'EOS'): 1,\n",
              " ('[', 'Verso', '3'): 1,\n",
              " ('Verso', '3', ':'): 1,\n",
              " ('3', ':', 'Jorge'): 1,\n",
              " ('BOS', 'Dios', 'era'): 1,\n",
              " ('Dios', 'era', 'la'): 1,\n",
              " ('era', 'la', 'letra'): 1,\n",
              " ('la', 'letra', 'chica'): 1,\n",
              " ('letra', 'chica', 'al'): 1,\n",
              " ('chica', 'al', 'final'): 1,\n",
              " ('al', 'final', 'del'): 1,\n",
              " ('final', 'del', 'papel'): 1,\n",
              " ('del', 'papel', 'EOS'): 1,\n",
              " ('BOS', 'Ya', 'no'): 1,\n",
              " ('Ya', 'no', 'contamos'): 1,\n",
              " ('no', 'contamos', 'con'): 1,\n",
              " ('contamos', 'con', 'Ã‰l'): 1,\n",
              " ('con', 'Ã‰l', 'EOS'): 1,\n",
              " ('BOS', 'Fin', 'de'): 1,\n",
              " ('Fin', 'de', 'la'): 1,\n",
              " ('de', 'la', 'Luna'): 1,\n",
              " ('la', 'Luna', 'de'): 1,\n",
              " ('Luna', 'de', 'miel'): 1,\n",
              " ('de', 'miel', 'EOS'): 1,\n",
              " ('BOS', 'Y', 'el'): 2,\n",
              " ('Y', 'el', 'libre'): 1,\n",
              " ('el', 'libre', 'albedrÃ­o'): 1,\n",
              " ('libre', 'albedrÃ­o', 'es'): 1,\n",
              " ('albedrÃ­o', 'es', 'un'): 1,\n",
              " ('es', 'un', 'cauce'): 1,\n",
              " ('un', 'cauce', 'vacÃ­o'): 1,\n",
              " ('cauce', 'vacÃ­o', 'EOS'): 1,\n",
              " ('BOS', 'Un', 'barco'): 1,\n",
              " ('Un', 'barco', 'que'): 1,\n",
              " ('barco', 'que', 'no'): 1,\n",
              " ('que', 'no', 'tiene'): 1,\n",
              " ('no', 'tiene', 'rÃ­o'): 1,\n",
              " ('tiene', 'rÃ­o', 'EOS'): 1,\n",
              " ('BOS', 'Ni', 'timonel'): 1,\n",
              " ('Ni', 'timonel', 'EOS'): 1,\n",
              " ('[', 'Verso', '4'): 1,\n",
              " ('Verso', '4', ':'): 1,\n",
              " ('4', ':', 'Jorge'): 1,\n",
              " ('BOS', 'Todos', 'aplauden'): 1,\n",
              " ('Todos', 'aplauden', ','): 1,\n",
              " ('aplauden', ',', 'tÃº'): 1,\n",
              " (',', 'tÃº', 'tambiÃ©n'): 1,\n",
              " ('tÃº', 'tambiÃ©n', 'EOS'): 1,\n",
              " ('BOS', 'Pero', 'no'): 1,\n",
              " ('Pero', 'no', 'queda'): 1,\n",
              " ('no', 'queda', 'claro'): 1,\n",
              " ('queda', 'claro', 'quiÃ©n'): 1,\n",
              " ('claro', 'quiÃ©n', 'EOS'): 1,\n",
              " ('BOS', 'Tiene', 'del'): 1,\n",
              " ('Tiene', 'del', 'mango'): 1,\n",
              " ('del', 'mango', 'a'): 1,\n",
              " ('mango', 'a', 'la'): 1,\n",
              " ('a', 'la', 'sartÃ©n'): 1,\n",
              " ('la', 'sartÃ©n', 'EOS'): 1,\n",
              " ('BOS', 'Del', 'sacrificio'): 1,\n",
              " ('Del', 'sacrificio', 'EOS'): 1,\n",
              " ('BOS', 'Piel', 'o'): 1,\n",
              " ('Piel', 'o', 'silicio'): 1,\n",
              " ('o', 'silicio', 'EOS'): 1,\n",
              " ('Y', 'el', 'precipicio'): 1,\n",
              " ('el', 'precipicio', 'EOS'): 1,\n",
              " ('BOS', 'Dice', ':'): 1,\n",
              " ('Dice', ':', 'Ven'): 1,\n",
              " (':', 'Ven', ','): 1,\n",
              " ('Ven', ',', 'ven'): 1,\n",
              " (',', 'ven', ','): 1,\n",
              " ('ven', ',', 'ven'): 1,\n",
              " (',', 'ven', 'EOS'): 1,\n",
              " ('BOS', '(', 'Dime'): 1,\n",
              " ('(', 'Dime', 'quÃ©'): 1,\n",
              " ('debo', 'cantar', ')'): 1,\n",
              " ('cantar', ')', 'EOS'): 1}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEpVPj21fs"
      },
      "source": [
        "Debe mostrar que su mÃ©todo funciona para $N = 1,2,3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzLfBLBk-i7"
      },
      "source": [
        "## P7. Perplexity (1 punto)\n",
        "\n",
        "En esta secciÃ³n evaluarÃ¡n su modelo de n-gramas y determinarÃ¡n la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
        "$$\n",
        "\n",
        "con $m$ el nÃºmero de oraciones del corpus y $M$ el tamaÃ±o del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas4KYhZ28_C"
      },
      "source": [
        "### 7.a Obtener probabilidades (0.5 puntos)\n",
        "\n",
        "En esta secciÃ³n implementarÃ¡ una funciÃ³n que determine la probabilidad de una oraciÃ³n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH0ScM44Jrb"
      },
      "source": [
        "Defina una funciÃ³n que reciba una oraciÃ³n, un diccionario con n-gramas y el valor de $n$. La funciÃ³n debe entregar la probabilidad de cualquier oraciÃ³n.\n",
        "\n",
        "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "aWGsq22H4Sxz"
      },
      "outputs": [],
      "source": [
        "def get_probability(sentence, ngram_model, n):\n",
        "    if len(sentence) < n:\n",
        "        return 1e-8\n",
        "\n",
        "    min_prob = 1e-8\n",
        "    probs = []\n",
        "\n",
        "    for i in range(len(sentence) - n + 1):\n",
        "        ngram = tuple(sentence[i:i + n])\n",
        "        prefix = ngram[:-1]\n",
        "\n",
        "        count_ngram = ngram_model.get(ngram, 0)\n",
        "        count_prefix = sum(v for k, v in ngram_model.items() if k[:-1] == prefix)\n",
        "\n",
        "        p = count_ngram / count_prefix if count_prefix > 0 else min_prob\n",
        "        probs.append(max(p, min_prob))\n",
        "\n",
        "    return float(np.prod(probs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1UkfOz75W_P"
      },
      "source": [
        "Pruebe su funciÃ³n con oraciones frecuentes y comente sus resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngram_model = n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8461538461538461"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(word_tokenize(\"BOS Â¿QuiÃ©n quiere que yo quiera lo que creo que quiero ? EOS\"), ngram_model, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0000000000000001e-40"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(word_tokenize(\"Existe algo asÃ­ en el texto realmente\"), ngram_model, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1e-08"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(word_tokenize(\"Jorge Drexler  \"), ngram_model, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las tres oraciones evaluadas ilustran distintos comportamientos del modelo trigram: la primera, altamente frecuente en el corpus, obtuvo una probabilidad elevada debido a que todos sus trigramas estÃ¡n presentes en el modelo; la segunda, inexistente en el entrenamiento, fue penalizada severamente con una probabilidad extremadamente baja por contener solo trigramas no observados; la tercera, al ser demasiado corta para formar trigramas, activa un caso borde y retorna directamente la probabilidad mÃ­nima asignada por defecto (1e-08)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnIFV7F3eOL"
      },
      "source": [
        "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
        "\n",
        "En esta sub-secciÃ³n deberÃ¡ calcular la perplejidad del corpus de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N21I_mPl5Cqx"
      },
      "source": [
        "Defina una funciÃ³n que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la funciÃ³n de la secciÃ³n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VC4Vbk3q5LsY"
      },
      "outputs": [],
      "source": [
        "def get_perplexity(corpus, n):\n",
        "    ngram_model = n_grams(train_corpus, n)\n",
        "\n",
        "    total_log_probs = []\n",
        "    total_tokens = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        tokens = word_tokenize(f'BOS {sentence.strip()} EOS')\n",
        "        total_tokens += len(tokens)\n",
        "        prob = get_probability(tokens, ngram_model, n)\n",
        "        log_prob = np.log2(prob) if prob > 0 else np.log2(1e-8)\n",
        "        total_log_probs.append(log_prob)\n",
        "\n",
        "    entropy = -np.sum(total_log_probs) / total_tokens\n",
        "    return float(2 ** entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OAjpRDoG5sUJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13.98616718737452"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_perplexity(test_corpus, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc07wXM5gyI"
      },
      "source": [
        "Nosotros interpretamos el valor de perplexity â‰ˆ 13,99 como una medida del grado de incertidumbre promedio que el modelo trigramas manifiesta al predecir las palabras del corpus de test. Este valor indica que, al enfrentarse a las secuencias lingÃ¼Ã­sticas del conjunto de prueba, el modelo considera en promedio unas 14 opciones posibles como continuaciones plausibles. La magnitud del resultado sugiere que el modelo logra capturar una porciÃ³n significativa de las regularidades del lenguaje en el corpus, aunque aÃºn conserva un margen de dispersiÃ³n en sus predicciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNsmR4OPQQX"
      },
      "source": [
        "## P8. InterpolaciÃ³n Lineal (0.5 puntos)\n",
        "\n",
        "Cree una funciÃ³n que obtenga la probabilidad de una oraciÃ³n interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que creÃ³ anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "X7kcWusAPPv5"
      },
      "outputs": [],
      "source": [
        "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from collections import Counter\n",
        "    import numpy as np\n",
        "\n",
        "    assert abs(l_1 + l_2 + l_3 - 1.0) < 1e-6, \"Los pesos deben sumar 1\"\n",
        "\n",
        "    # Modelos de n-gramas\n",
        "    model_1 = Counter(n_grams(corpus, 1))\n",
        "    model_2 = Counter(n_grams(corpus, 2))\n",
        "    model_3 = Counter(n_grams(corpus, 3))\n",
        "\n",
        "    total_1 = sum(model_1.values())\n",
        "    tokens = word_tokenize(f'BOS {sentence.strip()} EOS')\n",
        "    min_prob = 1e-8\n",
        "    probs = []\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "        w1 = tokens[i]\n",
        "        w2 = tokens[i - 1] if i >= 1 else None\n",
        "        w3 = tokens[i - 2] if i >= 2 else None\n",
        "\n",
        "        # Unigrama\n",
        "        p1 = model_1.get((w1,), 0) / total_1 if (w1,) in model_1 else 0\n",
        "\n",
        "        # Bigrama\n",
        "        if w2:\n",
        "            prefix_count = sum(v for k, v in model_2.items() if k[0] == w2)\n",
        "            p2 = model_2.get((w2, w1), 0) / prefix_count if prefix_count > 0 else 0\n",
        "        else:\n",
        "            p2 = 0\n",
        "\n",
        "        # Trigrama\n",
        "        if w2 and w3:\n",
        "            trigram_prefix = (w3, w2)\n",
        "            prefix_count = sum(v for k, v in model_3.items() if k[:2] == trigram_prefix)\n",
        "            p3 = model_3.get((w3, w2, w1), 0) / prefix_count if prefix_count > 0 else 0\n",
        "        else:\n",
        "            p3 = 0\n",
        "\n",
        "        interpolated = l_1 * p1 + l_2 * p2 + l_3 * p3\n",
        "        probs.append(max(interpolated, min_prob))\n",
        "\n",
        "    return float(np.prod(probs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1J_E77RQp3"
      },
      "source": [
        "Defina una funciÃ³n para calcular la perplejidad de un corpus con interpolaciÃ³n lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oAS94E1UROkg"
      },
      "outputs": [],
      "source": [
        "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
        "    \"\"\"\n",
        "    Calcula la perplejidad de un corpus de prueba utilizando interpolaciÃ³n lineal.\n",
        "\n",
        "    Args:\n",
        "        corpus (list[str]): Lista de oraciones (test_corpus).\n",
        "        l_1, l_2, l_3 (float): Pesos para unigramas, bigramas y trigramas (deben sumar 1).\n",
        "\n",
        "    Returns:\n",
        "        float: Valor de perplexity del corpus con interpolaciÃ³n.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "    total_log_prob = 0.0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        tokens = word_tokenize(f'BOS {sentence.strip()} EOS')\n",
        "        total_tokens += len(tokens)\n",
        "        prob = get_probability_lineal_interpol(sentence, train_corpus, l_1, l_2, l_3)\n",
        "        log_prob = np.log2(prob) if prob > 0 else np.log2(1e-8)\n",
        "        total_log_prob += log_prob\n",
        "\n",
        "    entropy = - total_log_prob / total_tokens\n",
        "    return float(2 ** entropy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoX9_o2SHOY"
      },
      "source": [
        "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EvaluaciÃ³n valores arbitrarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.76846587140421"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.33, 0.33, 0.34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20.28072362824061"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.1, 0.3, 0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32.268745617881706"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.6, 0.3, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19.689912632063717"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.1, 0.6, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.734592387217653"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.3, 0.6, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizando estas pruebas es posible apreciar que hay combinaciones de $\\lambda$ que entregan mejores resultados de perplexity que otros. AdemÃ¡s de indicar cual es n-grama que tiene mayor peso en la interpolaciÃ³n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EvaluaciÃ³n valores extemos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "OZ6-NA3AOUmq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "782.2597481383283"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 1, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39.35619117450112"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "450.352023599737"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que al asignar el 100% del peso a un solo modelo n-grama, la perplexity varÃ­a drÃ¡sticamente segÃºn el orden considerado. El modelo de unigramas $(1, 0, 0)$ alcanza una perplexity muy alta ($782.26$), lo que refleja su incapacidad para capturar dependencias contextuales. El bigrama $(0, 1, 0)$ ofrece el mejor desempeÃ±o ($39.36$), al equilibrar contexto y generalizaciÃ³n. En cambio, el trigrama $(0, 0, 1)$ sufre de sobreajuste, con una perplexity elevada ($450.35$), evidenciando que ningÃºn modelo extremo es Ã³ptimo por sÃ­ solo, y que la interpolaciÃ³n es clave para un balance eficaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por cuestiones de curiosidad quise saber el valor de todos los posibles valores sin entrar en los decimales tan exactos (aun) asÃ­ que diseÃ±e una funciÃ³n que encuentra la mejor interpolaciÃ³n dentro de todos los valores posibles de lambda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_interpolation(test_corpus):\n",
        "    best_perplexity = float('inf')\n",
        "    best_weights = None\n",
        "\n",
        "    for l1 in np.arange(0.0, 1.01, 0.1):\n",
        "        for l2 in np.arange(0.0, 1.01 - l1, 0.1):\n",
        "            l3 = round(1.0 - l1 - l2, 1)\n",
        "            if l3 < 0.0 or l3 > 1.0:\n",
        "                continue\n",
        "            try:\n",
        "                pp = get_pp_interpol(test_corpus, round(l1, 1), round(l2, 1), round(l3, 1))\n",
        "                if pp < best_perplexity:\n",
        "                    best_perplexity = pp\n",
        "                    best_weights = (round(l1, 1), round(l2, 1), round(l3, 1))\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "    return best_perplexity, best_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor perplexity: 19.666278810965135\n",
            "Pesos Ã³ptimos: Î»1=0.1, Î»2=0.5, Î»3=0.4\n"
          ]
        }
      ],
      "source": [
        "best_pp, best_lambdas = find_best_interpolation(test_corpus)\n",
        "print(f\"Mejor perplexity: {best_pp}\")\n",
        "print(f\"Pesos Ã³ptimos: Î»1={best_lambdas[0]}, Î»2={best_lambdas[1]}, Î»3={best_lambdas[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora con 2 decimales de exactitud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def refine_best_interpolation(test_corpus, best_weights, step=0.01, delta=0.05):\n",
        "    best_perplexity = float('inf')\n",
        "    best_refined_weights = None\n",
        "\n",
        "    l1_center, l2_center, _ = best_weights\n",
        "\n",
        "    # Definir rangos locales para l1 y l2\n",
        "    l1_range = np.round(np.arange(max(0.0, l1_center - delta), min(1.0, l1_center + delta) + step, step), 2)\n",
        "\n",
        "    for l1 in l1_range:\n",
        "        l2_max = 1.0 - l1\n",
        "        l2_range = np.round(np.arange(max(0.0, l2_center - delta), min(l2_max, l2_center + delta) + step, step), 2)\n",
        "\n",
        "        for l2 in l2_range:\n",
        "            l3 = round(1.0 - l1 - l2, 2)\n",
        "            if l3 < 0.0 or l3 > 1.0:\n",
        "                continue\n",
        "            try:\n",
        "                perplexity = get_pp_interpol(test_corpus, l1, l2, l3)\n",
        "                if perplexity < best_perplexity:\n",
        "                    best_perplexity = perplexity\n",
        "                    best_refined_weights = (l1, l2, l3)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    return best_perplexity, best_refined_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor perplexity refinada: 19.617784454120947\n",
            "Pesos Ã³ptimos refinados: Î»1=0.08, Î»2=0.55, Î»3=0.37\n"
          ]
        }
      ],
      "source": [
        "best_pp_1d, best_weights_1d = find_best_interpolation(test_corpus)\n",
        "\n",
        "best_pp_refined, best_weights_refined = refine_best_interpolation(test_corpus, best_weights_1d)\n",
        "\n",
        "print(f\"Mejor perplexity refinada: {best_pp_refined}\")\n",
        "print(f\"Pesos Ã³ptimos refinados: Î»1={best_weights_refined[0]}, Î»2={best_weights_refined[1]}, Î»3={best_weights_refined[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Curiosamente funcionÃ³, asÃ­ que para este caso, los mejores lambda son Î»1=0.08, Î»2=0.55, Î»3=0.37 para cada modelo de n-grama respectivamente. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
