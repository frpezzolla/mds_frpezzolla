{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxrkZWMLZB8z"
      },
      "source": [
        "# Tarea 1: Introducci√≥n, Modelos de Espacio Vectorial, Recuperaci√≥n de Informaci√≥n y Modelos de Lenguaje\n",
        "\n",
        "**Procesamiento de Lenguaje Natural (CC6205-1 - Oto√±o 2025)**\n",
        "\n",
        "## Tarjeta de Identificaci√≥n\n",
        "\n",
        "- **Nombre(s):** ```Israel Astudillo, Fabrizzio Pezolla, Rodrigo Molina```\n",
        "- **Fecha l√≠mite de entrega üìÜ:** 15 de abril de 2025\n",
        "- **Tiempo estimado de dedicaci√≥n:** 4 horas\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Instrucciones\n",
        "\n",
        "¬°Bienvenid@s a la primera tarea del curso de *Natural Language Processing* (NLP)!\n",
        "\n",
        "El objetivo de esta tarea es evaluar los conceptos te√≥ricos de las primeras semanas de clases, centr√°ndose en:\n",
        "\n",
        "- **Recuperaci√≥n de Informaci√≥n (IR)**\n",
        "- **Modelos de Espacio Vectorial**\n",
        "- **Modelos de Lenguaje**\n",
        "\n",
        "Si a√∫n no has revisado el contenido correspondiente, se recomienda consultar las referencias disponibles al final del documento.\n",
        "\n",
        "### üì¢ Consideraciones generales\n",
        "\n",
        "‚úÖ La tarea debe realizarse en **grupos de hasta 3 personas**.\n",
        "\n",
        "‚úÖ La entrega debe realizarse a trav√©s de **U-Cursos**, a m√°s tardar en la fecha estipulada. **No se aceptar√°n entregas atrasadas.**\n",
        "\n",
        "‚úÖ El formato de entrega es este mismo **Jupyter Notebook**.\n",
        "\n",
        "‚úÖ Su c√≥digo ser√° ejecutado al momento de la revisi√≥n. **Verifiquen que no tenga errores de compilaci√≥n.**\n",
        "\n",
        "‚úÖ Es obligatorio completar la **Tarjeta de Identificaci√≥n**. **No se asignar√° nota sin ella.**\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Material de Referencia\n",
        "\n",
        "### üìÑ Diapositivas del curso\n",
        "\n",
        "- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
        "- [Modelos de Espacio Vectorial y Recuperaci√≥n de Informaci√≥n](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)\n",
        "- [Modelos Probabil√≠sticos de Lenguaje](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-PLM.pdf)\n",
        "\n",
        "### üì∫ Videos del curso\n",
        "\n",
        "- **Introducci√≥n**: [Parte 1](https://www.youtube.com/watch?v=HEKTNOttGvU) | [Parte 2](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n",
        "- **Recuperaci√≥n de Informaci√≥n**: [Parte 1](https://www.youtube.com/watch?v=FXIVClF370w&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=f8nG1EMmPZk&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3)\n",
        "- **Modelos Probabil√≠sticos de Lenguaje**: [Parte 1](https://www.youtube.com/watch?v=9E2jJ6kcb4Y&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=3) | [Parte 2](https://www.youtube.com/watch?v=ZWqbEQXLra0&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=5) | [Parte 3](https://www.youtube.com/watch?v=tsumFqwFlaA&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJqBi&index=6) | [Parte 4](https://www.youtube.com/watch?v=s3TWdv4sqkg&list=PLppKo85eGXiXIh54H_qz48yHPHeNVJq)\n",
        "\n",
        "---\n",
        "\n",
        "üìå **Recuerda:** La claridad y organizaci√≥n en la entrega son clave para una mejor evaluaci√≥n. Incluir analisis apropiado. ¬°Mucho √©xito! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7w4BT1qmChV"
      },
      "source": [
        "## P1. Tokenizaci√≥n\n",
        "\n",
        "En el primer ejercicio veremos la dificultad de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlgSZrB2oe1H",
        "outputId": "9557a6fc-6737-496d-dfb6-7688e14eece8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ignorando conexi√≥n drive-colab\n"
          ]
        }
      ],
      "source": [
        "# En caso de desarrollar la tarea desde colab, con el siguiente c√≥digo podemos cargar los archivos desde drive:\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    path = '/content/drive/MyDrive/nlp/oh_algoritmo.txt'\n",
        "except:\n",
        "    print('Ignorando conexi√≥n drive-colab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCKFrnZcoy2F"
      },
      "source": [
        "Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9CteGwEmDKw",
        "outputId": "70a2043b-4a15-4650-f75e-2d458494d63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 1: Nora Erez]\n",
            "Wait, what's that money that you spent?\n",
            "What's that sitting on your plate?\n",
            "Do you want what you've been fed?\n",
            "Are you the fish or bait?\n",
            "Mmm, I'm on the top of the roof and I feel like a jail\n",
            "Rather not pay the bail\n",
            "To dangerous people with blood on their faces\n",
            "So I'm sharing a cell with the masses\n",
            "The underground always strive for the main\n",
            "Streaming like Grande's big-ass ring\n",
            "Screaming: I'll write you out my will\n",
            "Conscious is free, but not the will\n",
            "Conscious is free, but not the will\n",
            "You might also like\n",
            "Amor al Arte\n",
            "Jorge Drexler\n",
            "Tinta y Tiempo\n",
            "Jorge Drexler\n",
            "Asilo\n",
            "Jorge Drexler\n",
            "[Pre-Estribillo: Nora Erez]\n",
            "So if you want me to want what I believe that I want\n",
            "Can I choose to quit?\n",
            "\n",
            "[Estribillo: Jorge Drexler]\n",
            "Dime qu√© debo cantar\n",
            "Oh, algoritmo\n",
            "S√© que lo sabes mejor\n",
            "Incluso que yo mismo\n",
            "\n",
            "[Verso 2: Jorge Drexler]\n",
            "Por ejemplo, esta canci√≥n\n",
            "¬øQu√© algoritmo la pari√≥?\n",
            "Me pregunto si fui yo\n",
            "¬øLa elegiste o te eligi√≥?\n",
            "\n",
            "[Verso 3: Jorge Drexler]\n",
            "Dios era la letra chica al final del papel\n",
            "Ya no contamos con √âl\n",
            "Fin de la Luna de miel\n",
            "Y el libre albedr√≠o es un cauce vac√≠o\n",
            "Un barco que no tiene r√≠o\n",
            "Ni timonel\n",
            "\n",
            "[Verso 4: Jorge Drexler]\n",
            "Todos aplauden, t√∫ tambi√©n\n",
            "Pero no queda claro qui√©n\n",
            "Tiene del mango a la sart√©n\n",
            "Del sacrificio\n",
            "Piel o silicio\n",
            "Y el precipicio\n",
            "Dice: Ven, ven, ven\n",
            "[Refr√°n: Jorge Drexler]\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Dime qu√© debo cantar)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Oh, algoritmo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(S√© que lo sabes mejor)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Incluso que yo mismo)\n",
            "¬øQui√©n quiere que yo quiera lo que creo que quiero?\n",
            "(Wow)\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto)\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurri√≥ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPSSO2kJoArL"
      },
      "source": [
        "Fuente: https://genius.com/Jorge-drexler-oh-algoritmo-lyrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fG0hLbHg9dn"
      },
      "source": [
        "### Pregunta 1.a (0.25 puntos)\n",
        "\n",
        "Dise√±e una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Es libre de elegir la forma de tokenizar mientras no utilice librer√≠as con tokenizadores ya implementados. Puede utilizar la librer√≠a **re** importada para trabajar s√≠mbolos. Explique su razonamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5P7rk4VRm6Az"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qiRMkdjwazFT"
      },
      "outputs": [],
      "source": [
        "def get_tokens(texto):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    \"\"\"\n",
        "    get_tokens recibe un texto y entrega una lista con sus tokens.\n",
        "    [str]->list\n",
        "    \"\"\"\n",
        "    assert type(texto) == str, \"El texto debe ser un string\"\n",
        "    tokens = re.findall(r'\\w+|[^\\w\\s]', texto)\n",
        "    return tokens\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Of3bJ1tKo1Tp"
      },
      "outputs": [],
      "source": [
        "# Funci√≥n get_tokens alternativa\n",
        "def get_tokens_alt(texto):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    \"\"\"\n",
        "    get_tokens recibe un texto y entrega una lista con sus tokens.\n",
        "    [str]->list\n",
        "    \"\"\"\n",
        "    assert type(texto) == str, \"El texto debe ser un string\"\n",
        "    tokens = texto.split(sep=\" \")\n",
        "    for i in range(len(tokens)):\n",
        "      token = tokens[i]\n",
        "      token_limpio = re.sub(r'[^a-zA-Z]', '', token).lower()\n",
        "      tokens[i] = token_limpio\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "hDBZn4kOm7uH",
        "outputId": "c4fabe68-1cb6-4f5a-d225-db9990779676"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['letra',\n",
              " 'de',\n",
              " 'oh',\n",
              " 'algoritmo',\n",
              " 'ft',\n",
              " 'nora',\n",
              " 'erezrefrn',\n",
              " 'jorge',\n",
              " 'drexlerquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroestribillo',\n",
              " 'jorge',\n",
              " 'drexlerdime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantaroh',\n",
              " 'algoritmos',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoverso',\n",
              " '',\n",
              " 'nora',\n",
              " 'erezwait',\n",
              " 'whats',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spentwhats',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'platedo',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'youve',\n",
              " 'been',\n",
              " 'fedare',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'baitmmm',\n",
              " 'im',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'i',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jailrather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bailto',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'facesso',\n",
              " 'im',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'massesthe',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'mainstreaming',\n",
              " 'like',\n",
              " 'grandes',\n",
              " 'bigass',\n",
              " 'ringscreaming',\n",
              " 'ill',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'willconscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'willconscious',\n",
              " 'is',\n",
              " 'free',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'willyou',\n",
              " 'might',\n",
              " 'also',\n",
              " 'likeamor',\n",
              " 'al',\n",
              " 'artejorge',\n",
              " 'drexlertinta',\n",
              " 'y',\n",
              " 'tiempojorge',\n",
              " 'drexlerasilojorge',\n",
              " 'drexlerpreestribillo',\n",
              " 'nora',\n",
              " 'erezso',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'i',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'i',\n",
              " 'wantcan',\n",
              " 'i',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quitestribillo',\n",
              " 'jorge',\n",
              " 'drexlerdime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantaroh',\n",
              " 'algoritmos',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoverso',\n",
              " '',\n",
              " 'jorge',\n",
              " 'drexlerpor',\n",
              " 'ejemplo',\n",
              " 'esta',\n",
              " 'cancinqu',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'parime',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yola',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligiverso',\n",
              " '',\n",
              " 'jorge',\n",
              " 'drexlerdios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papelya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " 'lfin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'luna',\n",
              " 'de',\n",
              " 'miely',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedro',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vacoun',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'roni',\n",
              " 'timonelverso',\n",
              " '',\n",
              " 'jorge',\n",
              " 'drexlertodos',\n",
              " 'aplauden',\n",
              " 't',\n",
              " 'tambinpero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'quintiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sartndel',\n",
              " 'sacrificiopiel',\n",
              " 'o',\n",
              " 'silicioy',\n",
              " 'el',\n",
              " 'precipiciodice',\n",
              " 'ven',\n",
              " 'ven',\n",
              " 'venrefrn',\n",
              " 'jorge',\n",
              " 'drexlerquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierodime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantarquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierooh',\n",
              " 'algoritmoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieros',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierodime',\n",
              " 'qu',\n",
              " 'debo',\n",
              " 'cantarquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierooh',\n",
              " 'algoritmoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieros',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejorquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quieroincluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismoquin',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quierowow']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens_alt(texto)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CpZKljrotLa"
      },
      "source": [
        "### Pregunta 1.b (0.25 puntos)\n",
        "Explique su implementaci√≥n aqu√≠:\n",
        "> La implementaci√≥n utiliza la funci√≥n .findall de la librer√≠a re, que encuentra todas las apariciones del patr√≥n expresado en el primer argumento, en forma de expresi√≥n regular, en el texto insertado en el segundo argumento. La expresi√≥n regular utilizada es `r'\\w+|[^\\w\\s]'`. La letra r sirve para que la expresi√≥n no sea interpretada por python directamente como un comando y no utilice los s√≠mbolos de escape como \"\\\" directamente, sino que la expresi√≥n sea entregada tal cual. La expresi√≥n se divide en dos partes por el s√≠mbolo \"|\" que significa or l√≥gico. La primera parte `\\w+` significa uno o m√°s de un caracter alfanum√©rico de cualquier tipo, incluyendo guiones bajos. Esto captura conjuntos de letras como palabras y los distingue de cualquier otro separador como espacios, puntuaciones, entre otros. La segunda parte `[^\\w\\s]'` define una clase de caracteres con \"[ ]\", siendo la clase definida la negaci√≥n (denotado con \"^\") de los caracteres alfanum√©ricos y espacios blancos de cualquier tipo como tab, saltos de l√≠nea, entre otros. Es decir, esta clase captura todo lo que no sean caracteres alfanum√©ricos, guiones bajos y espacios blancos, lo cual deja solo los s√≠mbolos de puntuaci√≥n en general distinguidos como caracteres separados independientes. As√≠, en la salida de la funci√≥n esperamos palabras y s√≠mbolos de puntuaci√≥n, que es el resultado que se obtuvo.\n",
        "\n",
        "> La implementaci√≥n utiliza la funci√≥n .split nativa de python para separar el string en strings m√°s peque√±os utilizando √∫nicamente los espacios como separadores, retornando el resultado. Luego elimina todas los caracteres que no sean letras y transforma a min√∫scula el texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIwAKWZvofEp"
      },
      "source": [
        "Implementaci√≥n con la libreria NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_GR2Z0lnnPB9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Letra',\n",
              " 'de',\n",
              " '\"¬°',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'Algoritmo',\n",
              " '!\"',\n",
              " 'ft',\n",
              " '.',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " '[',\n",
              " 'Refr√°n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '1',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'Wait',\n",
              " ',',\n",
              " 'what',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'money',\n",
              " 'that',\n",
              " 'you',\n",
              " 'spent',\n",
              " '?',\n",
              " 'What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?',\n",
              " 'Mmm',\n",
              " ',',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'on',\n",
              " 'the',\n",
              " 'top',\n",
              " 'of',\n",
              " 'the',\n",
              " 'roof',\n",
              " 'and',\n",
              " 'I',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'a',\n",
              " 'jail',\n",
              " 'Rather',\n",
              " 'not',\n",
              " 'pay',\n",
              " 'the',\n",
              " 'bail',\n",
              " 'To',\n",
              " 'dangerous',\n",
              " 'people',\n",
              " 'with',\n",
              " 'blood',\n",
              " 'on',\n",
              " 'their',\n",
              " 'faces',\n",
              " 'So',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'm',\n",
              " 'sharing',\n",
              " 'a',\n",
              " 'cell',\n",
              " 'with',\n",
              " 'the',\n",
              " 'masses',\n",
              " 'The',\n",
              " 'underground',\n",
              " 'always',\n",
              " 'strive',\n",
              " 'for',\n",
              " 'the',\n",
              " 'main',\n",
              " 'Streaming',\n",
              " 'like',\n",
              " 'Grande',\n",
              " \"'\",\n",
              " 's',\n",
              " 'big',\n",
              " '-',\n",
              " 'ass',\n",
              " 'ring',\n",
              " 'Screaming',\n",
              " ':',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'll',\n",
              " 'write',\n",
              " 'you',\n",
              " 'out',\n",
              " 'my',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'Conscious',\n",
              " 'is',\n",
              " 'free',\n",
              " ',',\n",
              " 'but',\n",
              " 'not',\n",
              " 'the',\n",
              " 'will',\n",
              " 'You',\n",
              " 'might',\n",
              " 'also',\n",
              " 'like',\n",
              " 'Amor',\n",
              " 'al',\n",
              " 'Arte',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Tinta',\n",
              " 'y',\n",
              " 'Tiempo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " '[',\n",
              " 'Pre',\n",
              " '-',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Nora',\n",
              " 'Erez',\n",
              " ']',\n",
              " 'So',\n",
              " 'if',\n",
              " 'you',\n",
              " 'want',\n",
              " 'me',\n",
              " 'to',\n",
              " 'want',\n",
              " 'what',\n",
              " 'I',\n",
              " 'believe',\n",
              " 'that',\n",
              " 'I',\n",
              " 'want',\n",
              " 'Can',\n",
              " 'I',\n",
              " 'choose',\n",
              " 'to',\n",
              " 'quit',\n",
              " '?',\n",
              " '[',\n",
              " 'Estribillo',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " '[',\n",
              " 'Verso',\n",
              " '2',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Por',\n",
              " 'ejemplo',\n",
              " ',',\n",
              " 'esta',\n",
              " 'canci√≥n',\n",
              " '¬ø',\n",
              " 'Qu√©',\n",
              " 'algoritmo',\n",
              " 'la',\n",
              " 'pari√≥',\n",
              " '?',\n",
              " 'Me',\n",
              " 'pregunto',\n",
              " 'si',\n",
              " 'fui',\n",
              " 'yo',\n",
              " '¬ø',\n",
              " 'La',\n",
              " 'elegiste',\n",
              " 'o',\n",
              " 'te',\n",
              " 'eligi√≥',\n",
              " '?',\n",
              " '[',\n",
              " 'Verso',\n",
              " '3',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Dios',\n",
              " 'era',\n",
              " 'la',\n",
              " 'letra',\n",
              " 'chica',\n",
              " 'al',\n",
              " 'final',\n",
              " 'del',\n",
              " 'papel',\n",
              " 'Ya',\n",
              " 'no',\n",
              " 'contamos',\n",
              " 'con',\n",
              " '√âl',\n",
              " 'Fin',\n",
              " 'de',\n",
              " 'la',\n",
              " 'Luna',\n",
              " 'de',\n",
              " 'miel',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'libre',\n",
              " 'albedr√≠o',\n",
              " 'es',\n",
              " 'un',\n",
              " 'cauce',\n",
              " 'vac√≠o',\n",
              " 'Un',\n",
              " 'barco',\n",
              " 'que',\n",
              " 'no',\n",
              " 'tiene',\n",
              " 'r√≠o',\n",
              " 'Ni',\n",
              " 'timonel',\n",
              " '[',\n",
              " 'Verso',\n",
              " '4',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " 'Todos',\n",
              " 'aplauden',\n",
              " ',',\n",
              " 't√∫',\n",
              " 'tambi√©n',\n",
              " 'Pero',\n",
              " 'no',\n",
              " 'queda',\n",
              " 'claro',\n",
              " 'qui√©n',\n",
              " 'Tiene',\n",
              " 'del',\n",
              " 'mango',\n",
              " 'a',\n",
              " 'la',\n",
              " 'sart√©n',\n",
              " 'Del',\n",
              " 'sacrificio',\n",
              " 'Piel',\n",
              " 'o',\n",
              " 'silicio',\n",
              " 'Y',\n",
              " 'el',\n",
              " 'precipicio',\n",
              " 'Dice',\n",
              " ':',\n",
              " 'Ven',\n",
              " ',',\n",
              " 'ven',\n",
              " ',',\n",
              " 'ven',\n",
              " '[',\n",
              " 'Refr√°n',\n",
              " ':',\n",
              " 'Jorge',\n",
              " 'Drexler',\n",
              " ']',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Oh',\n",
              " ',',\n",
              " 'algoritmo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Incluso',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'mismo',\n",
              " ')',\n",
              " '¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " '(',\n",
              " 'Wow',\n",
              " ')']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "nltk_tokens = wordpunct_tokenize(texto)\n",
        "nltk_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3P4OeGn-qo"
      },
      "source": [
        "### Pregunta 1.c (0.5 puntos)\n",
        "¬øQu√© diferencias y similitudes encontrase al comparar la funci√≥n de tokenizaci√≥n creada manualmente por ti contra la implementaci√≥n de NLTK, al tokenizar la letra de la canci√≥n \"Oh, algoritmo\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E12BZ29JoFCp"
      },
      "source": [
        "> La diferencia con la implementaci√≥n de la librer√≠a es que no se reconocen caracteres especiales y algunas palabras no se diferencian correctamente. Por ejemplo el token \"drexlerpreestribillo\" no es un token adecuado en comparaci√≥n al resultado de la librer√≠a, por lo que no es un muy buen resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmUULnB6hWcl"
      },
      "source": [
        "## P2. Stemming y Stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LskhxOLdpT9q"
      },
      "source": [
        "En esta secci√≥n debera implementar funciones de stemming y stopwords basado en lo visto en clase. En la siguiente celda tiene el corpus que usara en esta secci√≥n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hj07_CmwhYxk"
      },
      "outputs": [],
      "source": [
        "# Corpus en espa√±ol\n",
        "corpus_espanol = [\n",
        "    \"¬øQui√©n quiere que yo quiera lo que creo que quiero?\",\n",
        "    \"Dime qu√© debo cantar\",\n",
        "    \"S√© que lo sabes mejor\"\n",
        "]\n",
        "\n",
        "# Corpus en ingl√©s\n",
        "corpus_ingles = [\n",
        "    \"What's that sitting on your plate?\",\n",
        "    \"Do you want what you've been fed?\",\n",
        "    \"Are you the fish or bait?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xRyOVbVWwJ5"
      },
      "source": [
        "### Pregunta 2.a (0.5 puntos)\n",
        "Implemente una funci√≥n **`get_vocab()`** que extraiga los tokens de un corpus. Puede utilizar la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F-727zL3ptDZ"
      },
      "outputs": [],
      "source": [
        "def get_vocab(corpus):\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  \"\"\"\n",
        "  get_tokens recibe un texto y entrega una lista con sus tokens.\n",
        "  [str]->list\n",
        "  \"\"\"\n",
        "  assert type(corpus) == str, \"El texto debe ser un string\"\n",
        "  tokens = re.findall(r'\\w+|[^\\w\\s]', corpus)\n",
        "  return tokens\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ge2cPS7fqYXy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['¬ø',\n",
              " 'Qui√©n',\n",
              " 'quiere',\n",
              " 'que',\n",
              " 'yo',\n",
              " 'quiera',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'creo',\n",
              " 'que',\n",
              " 'quiero',\n",
              " '?',\n",
              " 'Dime',\n",
              " 'qu√©',\n",
              " 'debo',\n",
              " 'cantar',\n",
              " 'S√©',\n",
              " 'que',\n",
              " 'lo',\n",
              " 'sabes',\n",
              " 'mejor']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_espanol = [get_vocab(vocab) for vocab in corpus_espanol]\n",
        "vocab_espanol = [palabra for sublista in vocab_espanol for palabra in sublista]\n",
        "vocab_espanol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCFtzHUbzJqt"
      },
      "source": [
        "Resultado esperado (el orden puede variar):\n",
        "```\n",
        "['yo', 'debo', 'creo', 'Dime', 'lo', 'cantar', 'mejor', 'S√©', 'que', 'quiere', 'quiero', 'sabes', 'Qui√©n', 'quiera', 'qu√©']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "apRK_d8uqlSm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What',\n",
              " \"'\",\n",
              " 's',\n",
              " 'that',\n",
              " 'sitting',\n",
              " 'on',\n",
              " 'your',\n",
              " 'plate',\n",
              " '?',\n",
              " 'Do',\n",
              " 'you',\n",
              " 'want',\n",
              " 'what',\n",
              " 'you',\n",
              " \"'\",\n",
              " 've',\n",
              " 'been',\n",
              " 'fed',\n",
              " '?',\n",
              " 'Are',\n",
              " 'you',\n",
              " 'the',\n",
              " 'fish',\n",
              " 'or',\n",
              " 'bait',\n",
              " '?']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_ingles = [get_vocab(vocab) for vocab in corpus_ingles]\n",
        "vocab_ingles = [palabra for sublista in vocab_ingles for palabra in sublista]\n",
        "vocab_ingles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvWMUQq5zPP8"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "['fed', 'been', 'or', 'want', 'plate', 'the', 've', 'your', 's', 'you', 'what', 'Are', 'bait', 'What', 'fish', 'that', 'sitting', 'Do', 'on']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVjU3cAzDkw"
      },
      "source": [
        "### Pregunta 2.b (0.5 puntos)\n",
        "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario preprocesado. Explique las reglas de stemming y elecci√≥n de stopwords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZSeU-rDYbI1"
      },
      "source": [
        "    Explique sus reglas aqu√≠: Primero se aplicar√° stemming para homogenizar las palabras en el corpus, de forma de luego contar la frecuencia de cada palabra para identificar stopwords sobre los tokens homogenizados.\n",
        "    \n",
        "    Para hacer stemming en el corpus en espa√±ol identificamos los verbos conjugados y les quitamos sus extremos del final. Podemos lograr esto eliminando las vocales o vocales + \"s\" del final de palabras largas o de m√°s de 4 caracteres.\n",
        "\n",
        "    En el corpus en ingl√©s podemos eliminar las terminaciones \"ing\" en este corpus en espec√≠fico. Podr√≠amos eliminar tambi√©n las \"s\" al final de las palabras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "777xbIG2sqy5"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocabulario, idioma):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    vowels = [\"a\", \"e\", \"i\", \"o\", \"u\"]\n",
        "    new_vocab = vocabulario.copy()\n",
        "\n",
        "    # Eliminar tokens no alfanum√©ricos\n",
        "    new_vocab = [p for p in new_vocab if p.isalnum()]\n",
        "\n",
        "    if idioma == \"espanol\":\n",
        "        # Stemming espa√±ol\n",
        "        for i in range(len(new_vocab)):\n",
        "            palabra = new_vocab[i]\n",
        "            if len(palabra) >= 4:\n",
        "                if palabra[-1] == \"s\" and palabra[-2] in vowels:\n",
        "                    palabra = palabra[:-2]  # vocal + s\n",
        "                elif palabra[-1] in vowels:\n",
        "                    palabra = palabra[:-1]\n",
        "                elif palabra[-1] == \"s\":\n",
        "                    palabra = palabra[:-1]\n",
        "            new_vocab[i] = palabra\n",
        "\n",
        "    elif idioma == \"ingles\":\n",
        "        # Stemming ingl√©s\n",
        "        for i in range(len(new_vocab)):\n",
        "            palabra = new_vocab[i]\n",
        "            if palabra.endswith(\"ing\") and len(palabra) > 4:\n",
        "                palabra = palabra[:-3]\n",
        "            elif palabra.endswith(\"s\") and len(palabra) > 3:\n",
        "                palabra = palabra[:-1]\n",
        "            new_vocab[i] = palabra\n",
        "\n",
        "    else:\n",
        "        raise Exception(\"Idioma no soportado\")\n",
        "\n",
        "    # Contar frecuencias para eliminar Stopwords\n",
        "    frec = {}\n",
        "    for palabra in new_vocab:\n",
        "        frec[palabra] = frec.get(palabra, 0) + 1\n",
        "\n",
        "    # Eliminar stopwords: palabras con >1 ocurrencia y largo <= 3\n",
        "    new_vocab = [p for p in new_vocab if not (frec[p] > 1 and len(p) <= 3)]\n",
        "    return new_vocab\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iT1Rr0das2Nb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulario procesado en espa√±ol: ['Qui√©n', 'quier', 'yo', 'quier', 'cre', 'quier', 'Dim', 'qu√©', 'deb', 'cantar', 'S√©', 'sab', 'mejor'] \n",
            "\n",
            "Vocabulario procesado en ingl√©s: ['What', 's', 'that', 'sitt', 'on', 'your', 'plate', 'Do', 'want', 'what', 've', 'been', 'fed', 'Are', 'the', 'fish', 'or', 'bait'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Aplicar preprocesamiento a los vocabularios de ejemplo con NLTK\n",
        "vocab_procesado_espanol = pre_processing(vocab_espanol, 'espanol')\n",
        "vocab_procesado_ingles = pre_processing(vocab_ingles, 'ingles')\n",
        "\n",
        "# Mostrar resultados\n",
        "print(\"Vocabulario procesado en espa√±ol:\", vocab_procesado_espanol, \"\\n\")\n",
        "print(\"Vocabulario procesado en ingl√©s:\", vocab_procesado_ingles, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajmn1HaNhZE9"
      },
      "source": [
        "## P3. Bag of Words (0.5 puntos)\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vT0XQM2Ghlvy"
      },
      "outputs": [],
      "source": [
        "d0 = 'El p√°jaro come semillas'\n",
        "d1 = 'El p√°jaro se despierta y canta'\n",
        "d2 = 'El p√°jaro canta y come semillas'\n",
        "d3 = 'El pez come y nada en el agua'\n",
        "d4 = 'El pez empieza a nadar'\n",
        "d5 = 'El pez come alimento'\n",
        "corpus = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeOOz1Su2ATf"
      },
      "source": [
        "El objetivo da las siguientes secciones es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica **TF-IDF**.\n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es la de **Bag of Words**, m√©todo mediante el cual se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci√≥n **`bag_of_words()`**, que recibe como input un arreglo de documentos y devuelve un dataframe de pandas con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representan las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el BoW de un documento.\n",
        "\n",
        "***Disclaimer: el orden de los resultados pueden variar.***\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente corpus:\n",
        "\n",
        "```\n",
        "corpus = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_njmcRPM2GpV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MENCbDO8s_ls"
      },
      "source": [
        "Implementar funci√≥n `bag_of_words()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "C_eRRUvD2ChD"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(corpus):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    from collections import Counter\n",
        "\n",
        "    bow_repr = {\n",
        "        f'd{idx}': Counter(doc.split())\n",
        "        for idx, doc in enumerate(corpus)\n",
        "        }\n",
        "\n",
        "    return pd.DataFrame(bow_repr).T.fillna(0).astype(int)\n",
        "\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "jWZyXGra2FOw",
        "outputId": "46e4e450-a73b-45ae-9aa4-e178ff5184cb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "El",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "p√°jaro",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "come",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "semillas",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "se",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "despierta",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "y",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "canta",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "pez",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "nada",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "en",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "el",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "agua",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "empieza",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "a",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "nadar",
                  "rawType": "int32",
                  "type": "integer"
                },
                {
                  "name": "alimento",
                  "rawType": "int32",
                  "type": "integer"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "c7c4afdb-78eb-4d7c-bba7-ea27726f3367",
              "rows": [
                [
                  "d0",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d2",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d3",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "1",
                  "1",
                  "1",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "d4",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "d5",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    El  p√°jaro  come  semillas  se  despierta  y  canta  pez  nada  en  el  \\\n",
              "d0   1       1     1         1   0          0  0      0    0     0   0   0   \n",
              "d1   1       1     0         0   1          1  1      1    0     0   0   0   \n",
              "d2   1       1     1         1   0          0  1      1    0     0   0   0   \n",
              "d3   1       0     1         0   0          0  1      0    1     1   1   1   \n",
              "d4   1       0     0         0   0          0  0      0    1     0   0   0   \n",
              "d5   1       0     1         0   0          0  0      0    1     0   0   0   \n",
              "\n",
              "    agua  empieza  a  nadar  alimento  \n",
              "d0     0        0  0      0         0  \n",
              "d1     0        0  0      0         0  \n",
              "d2     0        0  0      0         0  \n",
              "d3     1        0  0      0         0  \n",
              "d4     0        1  1      1         0  \n",
              "d5     0        0  0      0         1  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(corpus)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEA2Ic2sLlh"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMv3UZdRhgqT"
      },
      "source": [
        "## P4. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxW5CZjhoE9"
      },
      "source": [
        "### 4.a TF (0.25 puntos)\n",
        "\n",
        "Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia $\\max_i({\\text{tf}_{i,j}})$, donde\n",
        "$i$ corresponde al √≠ndice de las filas (BoW) y $j$ al de las columnas (palabras). Es decir, dividir cada BoW sobre la cantidad de veces de la palabra que aparezca m√°s veces en ese vector.\n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{\\max_i({\\text{tf}_{i,j})}}$$\n",
        "\n",
        "Implemente la funci√≥n `calc_tf(dataset_bow)`, que entrega la matriz de TF normalizada del BoW del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qQhnJuuShmR5"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    return dataset_bow.div(dataset_bow.max(axis='columns'), axis='index')\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "urDKFQVu2p3V",
        "outputId": "4e333698-99e7-4ae9-8928-7d13f45bab32"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "El",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "p√°jaro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "come",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "semillas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "se",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "despierta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "y",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "canta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pez",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nada",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "en",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "el",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "agua",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "empieza",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "a",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nadar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "alimento",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "675e2a09-6753-4021-9531-3a32d0bf3aa0",
              "rows": [
                [
                  "d0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d1",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d2",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d3",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d4",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "1.0",
                  "1.0",
                  "0.0"
                ],
                [
                  "d5",
                  "1.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "1.0"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     El  p√°jaro  come  semillas   se  despierta    y  canta  pez  nada   en  \\\n",
              "d0  1.0     1.0   1.0       1.0  0.0        0.0  0.0    0.0  0.0   0.0  0.0   \n",
              "d1  1.0     1.0   0.0       0.0  1.0        1.0  1.0    1.0  0.0   0.0  0.0   \n",
              "d2  1.0     1.0   1.0       1.0  0.0        0.0  1.0    1.0  0.0   0.0  0.0   \n",
              "d3  1.0     0.0   1.0       0.0  0.0        0.0  1.0    0.0  1.0   1.0  1.0   \n",
              "d4  1.0     0.0   0.0       0.0  0.0        0.0  0.0    0.0  1.0   0.0  0.0   \n",
              "d5  1.0     0.0   1.0       0.0  0.0        0.0  0.0    0.0  1.0   0.0  0.0   \n",
              "\n",
              "     el  agua  empieza    a  nadar  alimento  \n",
              "d0  0.0   0.0      0.0  0.0    0.0       0.0  \n",
              "d1  0.0   0.0      0.0  0.0    0.0       0.0  \n",
              "d2  0.0   0.0      0.0  0.0    0.0       0.0  \n",
              "d3  1.0   1.0      0.0  0.0    0.0       0.0  \n",
              "d4  0.0   0.0      1.0  1.0    1.0       0.0  \n",
              "d5  0.0   0.0      0.0  0.0    0.0       1.0  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swo3ZjwVtZlq"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |   el |   come |   a |   nadar |   se |   en |   y |   alimento |   semillas |   pez |   empieza |   canta |   agua |   nada |\n",
        "|:---|-----:|---------:|------------:|-----:|-------:|----:|--------:|-----:|-----:|----:|-----------:|-----------:|------:|----------:|--------:|-------:|-------:|\n",
        "| d0 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          0 |          1 |     0 |         0 |       0 |      0 |      0 |\n",
        "| d1 |    1 |        1 |           1 |    0 |      0 |   0 |       0 |    1 |    0 |   1 |          0 |          0 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d2 |    1 |        1 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   1 |          0 |          1 |     0 |         0 |       1 |      0 |      0 |\n",
        "| d3 |    1 |        0 |           0 |    1 |      1 |   0 |       0 |    0 |    1 |   1 |          0 |          0 |     1 |         0 |       0 |      1 |      1 |\n",
        "| d4 |    1 |        0 |           0 |    0 |      0 |   1 |       1 |    0 |    0 |   0 |          0 |          0 |     1 |         1 |       0 |      0 |      0 |\n",
        "| d5 |    1 |        0 |           0 |    0 |      1 |   0 |       0 |    0 |    0 |   0 |          1 |          0 |     1 |         0 |       0 |      0 |      0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh2bFyHFhpbM"
      },
      "source": [
        "### 4.b IDF (0.5 puntos)\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. √âsta debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el c√°lculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $\\text{idf}_{t_i} = \\log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ n√∫mero de documentos que contienen la palabra $t_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tGLjlSY02usu"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qoU4AIrm2sDT"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    N = dataset_bow.shape[0]\n",
        "    doc_counts = (dataset_bow > 0).sum(axis=0)\n",
        "    idf = np.log10(N / doc_counts)\n",
        "    return idf.to_dict()\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXPErPdw2uQx",
        "outputId": "82946019-d734-4bd3-b0ad-49e56178a6d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'El': 0.0,\n",
              " 'p√°jaro': 0.3010299956639812,\n",
              " 'come': 0.17609125905568124,\n",
              " 'semillas': 0.47712125471966244,\n",
              " 'se': 0.7781512503836436,\n",
              " 'despierta': 0.7781512503836436,\n",
              " 'y': 0.3010299956639812,\n",
              " 'canta': 0.47712125471966244,\n",
              " 'pez': 0.3010299956639812,\n",
              " 'nada': 0.7781512503836436,\n",
              " 'en': 0.7781512503836436,\n",
              " 'el': 0.7781512503836436,\n",
              " 'agua': 0.7781512503836436,\n",
              " 'empieza': 0.7781512503836436,\n",
              " 'a': 0.7781512503836436,\n",
              " 'nadar': 0.7781512503836436,\n",
              " 'alimento': 0.7781512503836436}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmp5lXdquAD1"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "{'El': 0.0,\n",
        " 'p√°jaro': 0.3010299956639812,\n",
        " 'despierta': 0.7781512503836436,\n",
        " 'el': 0.7781512503836436,\n",
        " 'come': 0.17609125905568124,\n",
        " 'a': 0.7781512503836436,\n",
        " 'nadar': 0.7781512503836436,\n",
        " 'se': 0.7781512503836436,\n",
        " 'en': 0.7781512503836436,\n",
        " 'y': 0.3010299956639812,\n",
        " 'alimento': 0.7781512503836436,\n",
        " 'semillas': 0.47712125471966244,\n",
        " 'pez': 0.3010299956639812,\n",
        " 'empieza': 0.7781512503836436,\n",
        " 'canta': 0.47712125471966244,\n",
        " 'agua': 0.7781512503836436,\n",
        " 'nada': 0.7781512503836436}\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-_vwiV20XL"
      },
      "source": [
        "### 4.c TF-IDF (0.25 puntos)\n",
        "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "004IuUyt23_6"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf, idf):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    return tf * idf\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "KXjP0S3626dw",
        "outputId": "05c27756-026b-46da-a5f2-88d30a52ae08"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "El",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "p√°jaro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "come",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "semillas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "se",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "despierta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "y",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "canta",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "pez",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nada",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "en",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "el",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "agua",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "empieza",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "a",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "nadar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "alimento",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "1d3eb3a4-e355-454d-9c2d-71bcc9b60060",
              "rows": [
                [
                  "d0",
                  "0.0",
                  "0.3010299956639812",
                  "0.17609125905568124",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d1",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.0",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.3010299956639812",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d2",
                  "0.0",
                  "0.3010299956639812",
                  "0.17609125905568124",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.47712125471966244",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d3",
                  "0.0",
                  "0.0",
                  "0.17609125905568124",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.3010299956639812",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "d4",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.7781512503836436",
                  "0.0"
                ],
                [
                  "d5",
                  "0.0",
                  "0.0",
                  "0.17609125905568124",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.3010299956639812",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.0",
                  "0.7781512503836436"
                ]
              ],
              "shape": {
                "columns": 17,
                "rows": 6
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>p√°jaro</th>\n",
              "      <th>come</th>\n",
              "      <th>semillas</th>\n",
              "      <th>se</th>\n",
              "      <th>despierta</th>\n",
              "      <th>y</th>\n",
              "      <th>canta</th>\n",
              "      <th>pez</th>\n",
              "      <th>nada</th>\n",
              "      <th>en</th>\n",
              "      <th>el</th>\n",
              "      <th>agua</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>nadar</th>\n",
              "      <th>alimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>d0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.30103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     El   p√°jaro      come  semillas        se  despierta        y     canta  \\\n",
              "d0  0.0  0.30103  0.176091  0.477121  0.000000   0.000000  0.00000  0.000000   \n",
              "d1  0.0  0.30103  0.000000  0.000000  0.778151   0.778151  0.30103  0.477121   \n",
              "d2  0.0  0.30103  0.176091  0.477121  0.000000   0.000000  0.30103  0.477121   \n",
              "d3  0.0  0.00000  0.176091  0.000000  0.000000   0.000000  0.30103  0.000000   \n",
              "d4  0.0  0.00000  0.000000  0.000000  0.000000   0.000000  0.00000  0.000000   \n",
              "d5  0.0  0.00000  0.176091  0.000000  0.000000   0.000000  0.00000  0.000000   \n",
              "\n",
              "        pez      nada        en        el      agua   empieza         a  \\\n",
              "d0  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "d1  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "d2  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "d3  0.30103  0.778151  0.778151  0.778151  0.778151  0.000000  0.000000   \n",
              "d4  0.30103  0.000000  0.000000  0.000000  0.000000  0.778151  0.778151   \n",
              "d5  0.30103  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "       nadar  alimento  \n",
              "d0  0.000000  0.000000  \n",
              "d1  0.000000  0.000000  \n",
              "d2  0.000000  0.000000  \n",
              "d3  0.000000  0.000000  \n",
              "d4  0.778151  0.000000  \n",
              "d5  0.000000  0.778151  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNTa32IsuLWl"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "\n",
        "|    |   El |   p√°jaro |   despierta |       el |     come |        a |    nadar |       se |       en |       y |   alimento |   semillas |     pez |   empieza |    canta |     agua |     nada |\n",
        "|:---|-----:|---------:|------------:|---------:|---------:|---------:|---------:|---------:|---------:|--------:|-----------:|-----------:|--------:|----------:|---------:|---------:|---------:|\n",
        "| d0 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0        |   0.477121 | 0       |  0        | 0        | 0        | 0        |\n",
        "| d1 |    0 |  0.30103 |    0.778151 | 0        | 0        | 0        | 0        | 0.778151 | 0        | 0.30103 |   0        |   0        | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d2 |    0 |  0.30103 |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0.30103 |   0        |   0.477121 | 0       |  0        | 0.477121 | 0        | 0        |\n",
        "| d3 |    0 |  0       |    0        | 0.778151 | 0.176091 | 0        | 0        | 0        | 0.778151 | 0.30103 |   0        |   0        | 0.30103 |  0        | 0        | 0.778151 | 0.778151 |\n",
        "| d4 |    0 |  0       |    0        | 0        | 0        | 0.778151 | 0.778151 | 0        | 0        | 0       |   0        |   0        | 0.30103 |  0.778151 | 0        | 0        | 0        |\n",
        "| d5 |    0 |  0       |    0        | 0        | 0.176091 | 0        | 0        | 0        | 0        | 0       |   0.778151 |   0        | 0.30103 |  0        | 0        | 0        | 0        |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8sQEjVshjQ7"
      },
      "source": [
        "## P5. Cosine-similarity (0.25 puntos)\n",
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica.\n",
        "\n",
        "Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos. Concluya cu√°les son los dos documentos m√°s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_68mo-BLhmuV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    return np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
        "    ### Aqu√≠ termina tu c√≥digo ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5z-23CN2_lU",
        "outputId": "c15b23a9-8e49-4570-a646-318527549199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El p√°jaro come semillas\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.7233435041520414 \n",
            "\n",
            "El p√°jaro se despierta y canta\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.3932010182312894 \n",
            "\n",
            "El p√°jaro canta y come semillas\n",
            "> Mas similar: El p√°jaro come semillas\n",
            "> Similitud: 0.7233435041520414 \n",
            "\n",
            "El pez come y nada en el agua\n",
            "> Mas similar: El p√°jaro canta y come semillas\n",
            "> Similitud: 0.09171890791406168 \n",
            "\n",
            "El pez empieza a nadar\n",
            "> Mas similar: El pez come alimento\n",
            "> Similitud: 0.07695078406752713 \n",
            "\n",
            "El pez come alimento\n",
            "> Mas similar: El pez come y nada en el agua\n",
            "> Similitud: 0.08787900372173231 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n",
        "\n",
        "for i in range(6):\n",
        "  mask = [k != i for k in range(6)]\n",
        "  j = np.argmax(similarity_matrix[i][mask])\n",
        "\n",
        "  print(corpus[i])\n",
        "  print(\"> Mas similar:\", np.array(corpus)[mask][j])\n",
        "  print(\"> Similitud:\", similarity_matrix[i][mask][j], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71oH4JHXulGQ"
      },
      "source": [
        "Soluci√≥n esperada:\n",
        "```\n",
        "El p√°jaro come semillas\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El p√°jaro se despierta y canta\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.39320101823128945\n",
        "\n",
        "El p√°jaro canta y come semillas\n",
        "> Mas similar: El p√°jaro come semillas\n",
        "> Similitud: 0.7233435041520414\n",
        "\n",
        "El pez come y nada en el agua\n",
        "> Mas similar: El p√°jaro canta y come semillas\n",
        "> Similitud: 0.09171890791406168\n",
        "\n",
        "El pez empieza a nadar\n",
        "> Mas similar: El pez come alimento\n",
        "> Similitud: 0.07695078406752713\n",
        "\n",
        "El pez come alimento\n",
        "> Mas similar: El pez come y nada en el agua\n",
        "> Similitud: 0.0878790037217323\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDZln45jfjMf"
      },
      "source": [
        "## P6 N-gramas (0.75 punto)\n",
        "\n",
        "En esta secci√≥n debera determinar los n-gramas del la cancion \"Oh algoritmo\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7duKoBvlSgg"
      },
      "source": [
        "### 6.a Corpus de entrenamiento y test (0.25 puntos)\n",
        "\n",
        "En esta subsecci√≥n debera definir el conjunto de entrenamiento y test de un corpus. Eliga una particion del 80% y 20% del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juDVurFfl3eZ",
        "outputId": "bf1f0dda-28c8-4ed3-d68d-5d27d497c65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]\n",
            "\n",
            "[Refr√°\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Abre el archivo en modo lectura (\"r\")\n",
        "    with open(\"oh_algoritmo.txt\", \"r\") as archivo:\n",
        "        # Lee el contenido del archivo\n",
        "        texto = archivo.read()\n",
        "        # Imprime el contenido\n",
        "        print(texto[:50])\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no se encuentra.\")\n",
        "except Exception as e:\n",
        "    print(\"Ocurri√≥ un error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYCw0AqOmlzD"
      },
      "source": [
        "Defina una funcion `get_sentences()` que entregue todas las oraciones del corpus que contengan al menos una palabra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "C88f9aVil9d_"
      },
      "outputs": [],
      "source": [
        "def get_sentences(texto):\n",
        "  ## Implementar aqu√≠\n",
        "  return [x for x in texto.split('\\n') if len(x.split(' '))>0 and len(x.split(' ')[0])>0]\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbZ8EhgHmR2c",
        "outputId": "e503f1a5-8c57-4fb6-8fca-5fccedaa18e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[Letra de \"¬°Oh, Algoritmo!\" ft. Nora Erez]',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 1: Nora Erez]',\n",
              " \"Wait, what's that money that you spent?\",\n",
              " \"What's that sitting on your plate?\",\n",
              " \"Do you want what you've been fed?\",\n",
              " 'Are you the fish or bait?',\n",
              " \"Mmm, I'm on the top of the roof and I feel like a jail\",\n",
              " 'Rather not pay the bail',\n",
              " 'To dangerous people with blood on their faces',\n",
              " \"So I'm sharing a cell with the masses\",\n",
              " 'The underground always strive for the main',\n",
              " \"Streaming like Grande's big-ass ring\",\n",
              " \"Screaming: I'll write you out my will\",\n",
              " 'Conscious is free, but not the will',\n",
              " 'Conscious is free, but not the will',\n",
              " 'You might also like',\n",
              " 'Amor al Arte',\n",
              " 'Jorge Drexler',\n",
              " 'Tinta y Tiempo',\n",
              " 'Jorge Drexler',\n",
              " 'Asilo',\n",
              " 'Jorge Drexler',\n",
              " '[Pre-Estribillo: Nora Erez]',\n",
              " 'So if you want me to want what I believe that I want',\n",
              " 'Can I choose to quit?',\n",
              " '[Estribillo: Jorge Drexler]',\n",
              " 'Dime qu√© debo cantar',\n",
              " 'Oh, algoritmo',\n",
              " 'S√© que lo sabes mejor',\n",
              " 'Incluso que yo mismo',\n",
              " '[Verso 2: Jorge Drexler]',\n",
              " 'Por ejemplo, esta canci√≥n',\n",
              " '¬øQu√© algoritmo la pari√≥?',\n",
              " 'Me pregunto si fui yo',\n",
              " '¬øLa elegiste o te eligi√≥?',\n",
              " '[Verso 3: Jorge Drexler]',\n",
              " 'Dios era la letra chica al final del papel',\n",
              " 'Ya no contamos con √âl',\n",
              " 'Fin de la Luna de miel',\n",
              " 'Y el libre albedr√≠o es un cauce vac√≠o',\n",
              " 'Un barco que no tiene r√≠o',\n",
              " 'Ni timonel',\n",
              " '[Verso 4: Jorge Drexler]',\n",
              " 'Todos aplauden, t√∫ tambi√©n',\n",
              " 'Pero no queda claro qui√©n',\n",
              " 'Tiene del mango a la sart√©n',\n",
              " 'Del sacrificio',\n",
              " 'Piel o silicio',\n",
              " 'Y el precipicio',\n",
              " 'Dice: Ven, ven, ven',\n",
              " '[Refr√°n: Jorge Drexler]',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Dime qu√© debo cantar)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Oh, algoritmo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(S√© que lo sabes mejor)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Incluso que yo mismo)',\n",
              " '¬øQui√©n quiere que yo quiera lo que creo que quiero?',\n",
              " '(Wow)']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oraciones_limpias = get_sentences(texto)\n",
        "oraciones_limpias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEBzcR6Ym0Us"
      },
      "source": [
        "Deber√≠a obtener en total 87 oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pDN1vGEmwRQ",
        "outputId": "7ecc8706-1e5b-4809-cb61-08c860d70458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(oraciones_limpias) == 87"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9dq8omm7cD"
      },
      "source": [
        "Ahora definiremos el conjunto de entrenamiento y prueba para las oraciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVHoR_-inEK1",
        "outputId": "de90d839-0d2e-410f-ab8a-eca02a3882f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(69, 18)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split = int(len(oraciones_limpias) * 0.8)\n",
        "train_corpus = oraciones_limpias[:split]\n",
        "test_corpus = oraciones_limpias[split:]\n",
        "\n",
        "len(train_corpus), len(test_corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csdw0qNsmjTF"
      },
      "source": [
        "### 6.b Estimaci√≥n de N-gramas (0.5 puntos)\n",
        "\n",
        "Defina una funci√≥n que reciba una lista de oraciones de un corpus y un N que indique el tama√±o de los N-gramas. La funci√≥n debe retornar un diccionario de Python donde la llave es un token (o palabra) y el valor es la cantidad de veces que ocurre el token, es decir, la frecuencia. En el caso de N-gramas con N mayor a 1 (como bi-gramas o tri-gramas) debe a√±adir un token especial al inicio o final de cada oraci√≥n seg√∫n corresponda (ver clases del curso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB2_1y1etIBF",
        "outputId": "0b5c7b06-bc8f-47c9-e447-b34495407154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\rodri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Lbrl3WVnmRzj"
      },
      "outputs": [],
      "source": [
        "def n_grams(corpus, n=3):\n",
        "  ## Implementar aqu√≠\n",
        "\n",
        "  assert n in [1,2,3]\n",
        "\n",
        "  token_lists = [\n",
        "      word_tokenize(f\"BOS {sent.strip()} EOS\") if n>1\n",
        "      else word_tokenize(sent)\n",
        "      for sent in corpus\n",
        "  ]\n",
        "\n",
        "  all_ngrams = [\n",
        "      tuple(tokens[i : i+n])\n",
        "      for tokens in token_lists\n",
        "      for i in range(len(tokens) - n + 1)\n",
        "  ]\n",
        "\n",
        "  freqs = Counter(all_ngrams) if n>1 else Counter(all_ngrams + [])\n",
        "\n",
        "  return dict(freqs)\n",
        "\n",
        "  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAoYncsp3C7u",
        "outputId": "cf08490d-e7d6-45c8-9027-39d6436a46f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('[',): 10,\n",
              " ('Letra',): 1,\n",
              " ('de',): 3,\n",
              " ('``',): 1,\n",
              " ('¬°Oh',): 1,\n",
              " (',',): 11,\n",
              " ('Algoritmo',): 1,\n",
              " ('!',): 1,\n",
              " (\"''\",): 1,\n",
              " ('ft.',): 1,\n",
              " ('Nora',): 3,\n",
              " ('Erez',): 3,\n",
              " (']',): 10,\n",
              " ('Refr√°n',): 2,\n",
              " (':',): 11,\n",
              " ('Jorge',): 10,\n",
              " ('Drexler',): 10,\n",
              " ('¬øQui√©n',): 11,\n",
              " ('quiere',): 11,\n",
              " ('que',): 38,\n",
              " ('yo',): 14,\n",
              " ('quiera',): 11,\n",
              " ('lo',): 13,\n",
              " ('creo',): 11,\n",
              " ('quiero',): 11,\n",
              " ('?',): 18,\n",
              " ('Estribillo',): 2,\n",
              " ('Dime',): 3,\n",
              " ('qu√©',): 3,\n",
              " ('debo',): 3,\n",
              " ('cantar',): 3,\n",
              " ('Oh',): 2,\n",
              " ('algoritmo',): 3,\n",
              " ('S√©',): 2,\n",
              " ('sabes',): 2,\n",
              " ('mejor',): 2,\n",
              " ('Incluso',): 2,\n",
              " ('mismo',): 2,\n",
              " ('Verso',): 4,\n",
              " ('1',): 1,\n",
              " ('Wait',): 1,\n",
              " ('what',): 3,\n",
              " (\"'s\",): 3,\n",
              " ('that',): 4,\n",
              " ('money',): 1,\n",
              " ('you',): 6,\n",
              " ('spent',): 1,\n",
              " ('What',): 1,\n",
              " ('sitting',): 1,\n",
              " ('on',): 3,\n",
              " ('your',): 1,\n",
              " ('plate',): 1,\n",
              " ('Do',): 1,\n",
              " ('want',): 4,\n",
              " (\"'ve\",): 1,\n",
              " ('been',): 1,\n",
              " ('fed',): 1,\n",
              " ('Are',): 1,\n",
              " ('the',): 8,\n",
              " ('fish',): 1,\n",
              " ('or',): 1,\n",
              " ('bait',): 1,\n",
              " ('Mmm',): 1,\n",
              " ('I',): 7,\n",
              " (\"'m\",): 2,\n",
              " ('top',): 1,\n",
              " ('of',): 1,\n",
              " ('roof',): 1,\n",
              " ('and',): 1,\n",
              " ('feel',): 1,\n",
              " ('like',): 3,\n",
              " ('a',): 3,\n",
              " ('jail',): 1,\n",
              " ('Rather',): 1,\n",
              " ('not',): 3,\n",
              " ('pay',): 1,\n",
              " ('bail',): 1,\n",
              " ('To',): 1,\n",
              " ('dangerous',): 1,\n",
              " ('people',): 1,\n",
              " ('with',): 2,\n",
              " ('blood',): 1,\n",
              " ('their',): 1,\n",
              " ('faces',): 1,\n",
              " ('So',): 2,\n",
              " ('sharing',): 1,\n",
              " ('cell',): 1,\n",
              " ('masses',): 1,\n",
              " ('The',): 1,\n",
              " ('underground',): 1,\n",
              " ('always',): 1,\n",
              " ('strive',): 1,\n",
              " ('for',): 1,\n",
              " ('main',): 1,\n",
              " ('Streaming',): 1,\n",
              " ('Grande',): 1,\n",
              " ('big-ass',): 1,\n",
              " ('ring',): 1,\n",
              " ('Screaming',): 1,\n",
              " (\"'ll\",): 1,\n",
              " ('write',): 1,\n",
              " ('out',): 1,\n",
              " ('my',): 1,\n",
              " ('will',): 3,\n",
              " ('Conscious',): 2,\n",
              " ('is',): 2,\n",
              " ('free',): 2,\n",
              " ('but',): 2,\n",
              " ('You',): 1,\n",
              " ('might',): 1,\n",
              " ('also',): 1,\n",
              " ('Amor',): 1,\n",
              " ('al',): 2,\n",
              " ('Arte',): 1,\n",
              " ('Tinta',): 1,\n",
              " ('y',): 1,\n",
              " ('Tiempo',): 1,\n",
              " ('Asilo',): 1,\n",
              " ('Pre-Estribillo',): 1,\n",
              " ('if',): 1,\n",
              " ('me',): 1,\n",
              " ('to',): 2,\n",
              " ('believe',): 1,\n",
              " ('Can',): 1,\n",
              " ('choose',): 1,\n",
              " ('quit',): 1,\n",
              " ('2',): 1,\n",
              " ('Por',): 1,\n",
              " ('ejemplo',): 1,\n",
              " ('esta',): 1,\n",
              " ('canci√≥n',): 1,\n",
              " ('¬øQu√©',): 1,\n",
              " ('la',): 4,\n",
              " ('pari√≥',): 1,\n",
              " ('Me',): 1,\n",
              " ('pregunto',): 1,\n",
              " ('si',): 1,\n",
              " ('fui',): 1,\n",
              " ('¬øLa',): 1,\n",
              " ('elegiste',): 1,\n",
              " ('o',): 2,\n",
              " ('te',): 1,\n",
              " ('eligi√≥',): 1,\n",
              " ('3',): 1,\n",
              " ('Dios',): 1,\n",
              " ('era',): 1,\n",
              " ('letra',): 1,\n",
              " ('chica',): 1,\n",
              " ('final',): 1,\n",
              " ('del',): 2,\n",
              " ('papel',): 1,\n",
              " ('Ya',): 1,\n",
              " ('no',): 3,\n",
              " ('contamos',): 1,\n",
              " ('con',): 1,\n",
              " ('√âl',): 1,\n",
              " ('Fin',): 1,\n",
              " ('Luna',): 1,\n",
              " ('miel',): 1,\n",
              " ('Y',): 2,\n",
              " ('el',): 2,\n",
              " ('libre',): 1,\n",
              " ('albedr√≠o',): 1,\n",
              " ('es',): 1,\n",
              " ('un',): 1,\n",
              " ('cauce',): 1,\n",
              " ('vac√≠o',): 1,\n",
              " ('Un',): 1,\n",
              " ('barco',): 1,\n",
              " ('tiene',): 1,\n",
              " ('r√≠o',): 1,\n",
              " ('Ni',): 1,\n",
              " ('timonel',): 1,\n",
              " ('4',): 1,\n",
              " ('Todos',): 1,\n",
              " ('aplauden',): 1,\n",
              " ('t√∫',): 1,\n",
              " ('tambi√©n',): 1,\n",
              " ('Pero',): 1,\n",
              " ('queda',): 1,\n",
              " ('claro',): 1,\n",
              " ('qui√©n',): 1,\n",
              " ('Tiene',): 1,\n",
              " ('mango',): 1,\n",
              " ('sart√©n',): 1,\n",
              " ('Del',): 1,\n",
              " ('sacrificio',): 1,\n",
              " ('Piel',): 1,\n",
              " ('silicio',): 1,\n",
              " ('precipicio',): 1,\n",
              " ('Dice',): 1,\n",
              " ('Ven',): 1,\n",
              " ('ven',): 2,\n",
              " ('(',): 1,\n",
              " (')',): 1}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8XDEuRF3Grx",
        "outputId": "80e595f0-9ae9-4bab-d340-bcdc5987afdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('BOS', '['): 10,\n",
              " ('[', 'Letra'): 1,\n",
              " ('Letra', 'de'): 1,\n",
              " ('de', '``'): 1,\n",
              " ('``', '¬°Oh'): 1,\n",
              " ('¬°Oh', ','): 1,\n",
              " (',', 'Algoritmo'): 1,\n",
              " ('Algoritmo', '!'): 1,\n",
              " ('!', \"''\"): 1,\n",
              " (\"''\", 'ft.'): 1,\n",
              " ('ft.', 'Nora'): 1,\n",
              " ('Nora', 'Erez'): 3,\n",
              " ('Erez', ']'): 3,\n",
              " (']', 'EOS'): 10,\n",
              " ('[', 'Refr√°n'): 2,\n",
              " ('Refr√°n', ':'): 2,\n",
              " (':', 'Jorge'): 7,\n",
              " ('Jorge', 'Drexler'): 10,\n",
              " ('Drexler', ']'): 7,\n",
              " ('BOS', '¬øQui√©n'): 11,\n",
              " ('¬øQui√©n', 'quiere'): 11,\n",
              " ('quiere', 'que'): 11,\n",
              " ('que', 'yo'): 13,\n",
              " ('yo', 'quiera'): 11,\n",
              " ('quiera', 'lo'): 11,\n",
              " ('lo', 'que'): 11,\n",
              " ('que', 'creo'): 11,\n",
              " ('creo', 'que'): 11,\n",
              " ('que', 'quiero'): 11,\n",
              " ('quiero', '?'): 11,\n",
              " ('?', 'EOS'): 18,\n",
              " ('[', 'Estribillo'): 2,\n",
              " ('Estribillo', ':'): 2,\n",
              " ('BOS', 'Dime'): 2,\n",
              " ('Dime', 'qu√©'): 3,\n",
              " ('qu√©', 'debo'): 3,\n",
              " ('debo', 'cantar'): 3,\n",
              " ('cantar', 'EOS'): 2,\n",
              " ('BOS', 'Oh'): 2,\n",
              " ('Oh', ','): 2,\n",
              " (',', 'algoritmo'): 2,\n",
              " ('algoritmo', 'EOS'): 2,\n",
              " ('BOS', 'S√©'): 2,\n",
              " ('S√©', 'que'): 2,\n",
              " ('que', 'lo'): 2,\n",
              " ('lo', 'sabes'): 2,\n",
              " ('sabes', 'mejor'): 2,\n",
              " ('mejor', 'EOS'): 2,\n",
              " ('BOS', 'Incluso'): 2,\n",
              " ('Incluso', 'que'): 2,\n",
              " ('yo', 'mismo'): 2,\n",
              " ('mismo', 'EOS'): 2,\n",
              " ('[', 'Verso'): 4,\n",
              " ('Verso', '1'): 1,\n",
              " ('1', ':'): 1,\n",
              " (':', 'Nora'): 2,\n",
              " ('BOS', 'Wait'): 1,\n",
              " ('Wait', ','): 1,\n",
              " (',', 'what'): 1,\n",
              " ('what', \"'s\"): 1,\n",
              " (\"'s\", 'that'): 2,\n",
              " ('that', 'money'): 1,\n",
              " ('money', 'that'): 1,\n",
              " ('that', 'you'): 1,\n",
              " ('you', 'spent'): 1,\n",
              " ('spent', '?'): 1,\n",
              " ('BOS', 'What'): 1,\n",
              " ('What', \"'s\"): 1,\n",
              " ('that', 'sitting'): 1,\n",
              " ('sitting', 'on'): 1,\n",
              " ('on', 'your'): 1,\n",
              " ('your', 'plate'): 1,\n",
              " ('plate', '?'): 1,\n",
              " ('BOS', 'Do'): 1,\n",
              " ('Do', 'you'): 1,\n",
              " ('you', 'want'): 2,\n",
              " ('want', 'what'): 2,\n",
              " ('what', 'you'): 1,\n",
              " ('you', \"'ve\"): 1,\n",
              " (\"'ve\", 'been'): 1,\n",
              " ('been', 'fed'): 1,\n",
              " ('fed', '?'): 1,\n",
              " ('BOS', 'Are'): 1,\n",
              " ('Are', 'you'): 1,\n",
              " ('you', 'the'): 1,\n",
              " ('the', 'fish'): 1,\n",
              " ('fish', 'or'): 1,\n",
              " ('or', 'bait'): 1,\n",
              " ('bait', '?'): 1,\n",
              " ('BOS', 'Mmm'): 1,\n",
              " ('Mmm', ','): 1,\n",
              " (',', 'I'): 1,\n",
              " ('I', \"'m\"): 2,\n",
              " (\"'m\", 'on'): 1,\n",
              " ('on', 'the'): 1,\n",
              " ('the', 'top'): 1,\n",
              " ('top', 'of'): 1,\n",
              " ('of', 'the'): 1,\n",
              " ('the', 'roof'): 1,\n",
              " ('roof', 'and'): 1,\n",
              " ('and', 'I'): 1,\n",
              " ('I', 'feel'): 1,\n",
              " ('feel', 'like'): 1,\n",
              " ('like', 'a'): 1,\n",
              " ('a', 'jail'): 1,\n",
              " ('jail', 'EOS'): 1,\n",
              " ('BOS', 'Rather'): 1,\n",
              " ('Rather', 'not'): 1,\n",
              " ('not', 'pay'): 1,\n",
              " ('pay', 'the'): 1,\n",
              " ('the', 'bail'): 1,\n",
              " ('bail', 'EOS'): 1,\n",
              " ('BOS', 'To'): 1,\n",
              " ('To', 'dangerous'): 1,\n",
              " ('dangerous', 'people'): 1,\n",
              " ('people', 'with'): 1,\n",
              " ('with', 'blood'): 1,\n",
              " ('blood', 'on'): 1,\n",
              " ('on', 'their'): 1,\n",
              " ('their', 'faces'): 1,\n",
              " ('faces', 'EOS'): 1,\n",
              " ('BOS', 'So'): 2,\n",
              " ('So', 'I'): 1,\n",
              " (\"'m\", 'sharing'): 1,\n",
              " ('sharing', 'a'): 1,\n",
              " ('a', 'cell'): 1,\n",
              " ('cell', 'with'): 1,\n",
              " ('with', 'the'): 1,\n",
              " ('the', 'masses'): 1,\n",
              " ('masses', 'EOS'): 1,\n",
              " ('BOS', 'The'): 1,\n",
              " ('The', 'underground'): 1,\n",
              " ('underground', 'always'): 1,\n",
              " ('always', 'strive'): 1,\n",
              " ('strive', 'for'): 1,\n",
              " ('for', 'the'): 1,\n",
              " ('the', 'main'): 1,\n",
              " ('main', 'EOS'): 1,\n",
              " ('BOS', 'Streaming'): 1,\n",
              " ('Streaming', 'like'): 1,\n",
              " ('like', 'Grande'): 1,\n",
              " ('Grande', \"'s\"): 1,\n",
              " (\"'s\", 'big-ass'): 1,\n",
              " ('big-ass', 'ring'): 1,\n",
              " ('ring', 'EOS'): 1,\n",
              " ('BOS', 'Screaming'): 1,\n",
              " ('Screaming', ':'): 1,\n",
              " (':', 'I'): 1,\n",
              " ('I', \"'ll\"): 1,\n",
              " (\"'ll\", 'write'): 1,\n",
              " ('write', 'you'): 1,\n",
              " ('you', 'out'): 1,\n",
              " ('out', 'my'): 1,\n",
              " ('my', 'will'): 1,\n",
              " ('will', 'EOS'): 3,\n",
              " ('BOS', 'Conscious'): 2,\n",
              " ('Conscious', 'is'): 2,\n",
              " ('is', 'free'): 2,\n",
              " ('free', ','): 2,\n",
              " (',', 'but'): 2,\n",
              " ('but', 'not'): 2,\n",
              " ('not', 'the'): 2,\n",
              " ('the', 'will'): 2,\n",
              " ('BOS', 'You'): 1,\n",
              " ('You', 'might'): 1,\n",
              " ('might', 'also'): 1,\n",
              " ('also', 'like'): 1,\n",
              " ('like', 'EOS'): 1,\n",
              " ('BOS', 'Amor'): 1,\n",
              " ('Amor', 'al'): 1,\n",
              " ('al', 'Arte'): 1,\n",
              " ('Arte', 'EOS'): 1,\n",
              " ('BOS', 'Jorge'): 3,\n",
              " ('Drexler', 'EOS'): 3,\n",
              " ('BOS', 'Tinta'): 1,\n",
              " ('Tinta', 'y'): 1,\n",
              " ('y', 'Tiempo'): 1,\n",
              " ('Tiempo', 'EOS'): 1,\n",
              " ('BOS', 'Asilo'): 1,\n",
              " ('Asilo', 'EOS'): 1,\n",
              " ('[', 'Pre-Estribillo'): 1,\n",
              " ('Pre-Estribillo', ':'): 1,\n",
              " ('So', 'if'): 1,\n",
              " ('if', 'you'): 1,\n",
              " ('want', 'me'): 1,\n",
              " ('me', 'to'): 1,\n",
              " ('to', 'want'): 1,\n",
              " ('what', 'I'): 1,\n",
              " ('I', 'believe'): 1,\n",
              " ('believe', 'that'): 1,\n",
              " ('that', 'I'): 1,\n",
              " ('I', 'want'): 1,\n",
              " ('want', 'EOS'): 1,\n",
              " ('BOS', 'Can'): 1,\n",
              " ('Can', 'I'): 1,\n",
              " ('I', 'choose'): 1,\n",
              " ('choose', 'to'): 1,\n",
              " ('to', 'quit'): 1,\n",
              " ('quit', '?'): 1,\n",
              " ('Verso', '2'): 1,\n",
              " ('2', ':'): 1,\n",
              " ('BOS', 'Por'): 1,\n",
              " ('Por', 'ejemplo'): 1,\n",
              " ('ejemplo', ','): 1,\n",
              " (',', 'esta'): 1,\n",
              " ('esta', 'canci√≥n'): 1,\n",
              " ('canci√≥n', 'EOS'): 1,\n",
              " ('BOS', '¬øQu√©'): 1,\n",
              " ('¬øQu√©', 'algoritmo'): 1,\n",
              " ('algoritmo', 'la'): 1,\n",
              " ('la', 'pari√≥'): 1,\n",
              " ('pari√≥', '?'): 1,\n",
              " ('BOS', 'Me'): 1,\n",
              " ('Me', 'pregunto'): 1,\n",
              " ('pregunto', 'si'): 1,\n",
              " ('si', 'fui'): 1,\n",
              " ('fui', 'yo'): 1,\n",
              " ('yo', 'EOS'): 1,\n",
              " ('BOS', '¬øLa'): 1,\n",
              " ('¬øLa', 'elegiste'): 1,\n",
              " ('elegiste', 'o'): 1,\n",
              " ('o', 'te'): 1,\n",
              " ('te', 'eligi√≥'): 1,\n",
              " ('eligi√≥', '?'): 1,\n",
              " ('Verso', '3'): 1,\n",
              " ('3', ':'): 1,\n",
              " ('BOS', 'Dios'): 1,\n",
              " ('Dios', 'era'): 1,\n",
              " ('era', 'la'): 1,\n",
              " ('la', 'letra'): 1,\n",
              " ('letra', 'chica'): 1,\n",
              " ('chica', 'al'): 1,\n",
              " ('al', 'final'): 1,\n",
              " ('final', 'del'): 1,\n",
              " ('del', 'papel'): 1,\n",
              " ('papel', 'EOS'): 1,\n",
              " ('BOS', 'Ya'): 1,\n",
              " ('Ya', 'no'): 1,\n",
              " ('no', 'contamos'): 1,\n",
              " ('contamos', 'con'): 1,\n",
              " ('con', '√âl'): 1,\n",
              " ('√âl', 'EOS'): 1,\n",
              " ('BOS', 'Fin'): 1,\n",
              " ('Fin', 'de'): 1,\n",
              " ('de', 'la'): 1,\n",
              " ('la', 'Luna'): 1,\n",
              " ('Luna', 'de'): 1,\n",
              " ('de', 'miel'): 1,\n",
              " ('miel', 'EOS'): 1,\n",
              " ('BOS', 'Y'): 2,\n",
              " ('Y', 'el'): 2,\n",
              " ('el', 'libre'): 1,\n",
              " ('libre', 'albedr√≠o'): 1,\n",
              " ('albedr√≠o', 'es'): 1,\n",
              " ('es', 'un'): 1,\n",
              " ('un', 'cauce'): 1,\n",
              " ('cauce', 'vac√≠o'): 1,\n",
              " ('vac√≠o', 'EOS'): 1,\n",
              " ('BOS', 'Un'): 1,\n",
              " ('Un', 'barco'): 1,\n",
              " ('barco', 'que'): 1,\n",
              " ('que', 'no'): 1,\n",
              " ('no', 'tiene'): 1,\n",
              " ('tiene', 'r√≠o'): 1,\n",
              " ('r√≠o', 'EOS'): 1,\n",
              " ('BOS', 'Ni'): 1,\n",
              " ('Ni', 'timonel'): 1,\n",
              " ('timonel', 'EOS'): 1,\n",
              " ('Verso', '4'): 1,\n",
              " ('4', ':'): 1,\n",
              " ('BOS', 'Todos'): 1,\n",
              " ('Todos', 'aplauden'): 1,\n",
              " ('aplauden', ','): 1,\n",
              " (',', 't√∫'): 1,\n",
              " ('t√∫', 'tambi√©n'): 1,\n",
              " ('tambi√©n', 'EOS'): 1,\n",
              " ('BOS', 'Pero'): 1,\n",
              " ('Pero', 'no'): 1,\n",
              " ('no', 'queda'): 1,\n",
              " ('queda', 'claro'): 1,\n",
              " ('claro', 'qui√©n'): 1,\n",
              " ('qui√©n', 'EOS'): 1,\n",
              " ('BOS', 'Tiene'): 1,\n",
              " ('Tiene', 'del'): 1,\n",
              " ('del', 'mango'): 1,\n",
              " ('mango', 'a'): 1,\n",
              " ('a', 'la'): 1,\n",
              " ('la', 'sart√©n'): 1,\n",
              " ('sart√©n', 'EOS'): 1,\n",
              " ('BOS', 'Del'): 1,\n",
              " ('Del', 'sacrificio'): 1,\n",
              " ('sacrificio', 'EOS'): 1,\n",
              " ('BOS', 'Piel'): 1,\n",
              " ('Piel', 'o'): 1,\n",
              " ('o', 'silicio'): 1,\n",
              " ('silicio', 'EOS'): 1,\n",
              " ('el', 'precipicio'): 1,\n",
              " ('precipicio', 'EOS'): 1,\n",
              " ('BOS', 'Dice'): 1,\n",
              " ('Dice', ':'): 1,\n",
              " (':', 'Ven'): 1,\n",
              " ('Ven', ','): 1,\n",
              " (',', 'ven'): 2,\n",
              " ('ven', ','): 1,\n",
              " ('ven', 'EOS'): 1,\n",
              " ('BOS', '('): 1,\n",
              " ('(', 'Dime'): 1,\n",
              " ('cantar', ')'): 1,\n",
              " (')', 'EOS'): 1}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCpbhiXp3Gpg",
        "outputId": "cab2df5b-cfad-482a-dfac-1dcf3ddb4942"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('BOS', '[', 'Letra'): 1,\n",
              " ('[', 'Letra', 'de'): 1,\n",
              " ('Letra', 'de', '``'): 1,\n",
              " ('de', '``', '¬°Oh'): 1,\n",
              " ('``', '¬°Oh', ','): 1,\n",
              " ('¬°Oh', ',', 'Algoritmo'): 1,\n",
              " (',', 'Algoritmo', '!'): 1,\n",
              " ('Algoritmo', '!', \"''\"): 1,\n",
              " ('!', \"''\", 'ft.'): 1,\n",
              " (\"''\", 'ft.', 'Nora'): 1,\n",
              " ('ft.', 'Nora', 'Erez'): 1,\n",
              " ('Nora', 'Erez', ']'): 3,\n",
              " ('Erez', ']', 'EOS'): 3,\n",
              " ('BOS', '[', 'Refr√°n'): 2,\n",
              " ('[', 'Refr√°n', ':'): 2,\n",
              " ('Refr√°n', ':', 'Jorge'): 2,\n",
              " (':', 'Jorge', 'Drexler'): 7,\n",
              " ('Jorge', 'Drexler', ']'): 7,\n",
              " ('Drexler', ']', 'EOS'): 7,\n",
              " ('BOS', '¬øQui√©n', 'quiere'): 11,\n",
              " ('¬øQui√©n', 'quiere', 'que'): 11,\n",
              " ('quiere', 'que', 'yo'): 11,\n",
              " ('que', 'yo', 'quiera'): 11,\n",
              " ('yo', 'quiera', 'lo'): 11,\n",
              " ('quiera', 'lo', 'que'): 11,\n",
              " ('lo', 'que', 'creo'): 11,\n",
              " ('que', 'creo', 'que'): 11,\n",
              " ('creo', 'que', 'quiero'): 11,\n",
              " ('que', 'quiero', '?'): 11,\n",
              " ('quiero', '?', 'EOS'): 11,\n",
              " ('BOS', '[', 'Estribillo'): 2,\n",
              " ('[', 'Estribillo', ':'): 2,\n",
              " ('Estribillo', ':', 'Jorge'): 2,\n",
              " ('BOS', 'Dime', 'qu√©'): 2,\n",
              " ('Dime', 'qu√©', 'debo'): 3,\n",
              " ('qu√©', 'debo', 'cantar'): 3,\n",
              " ('debo', 'cantar', 'EOS'): 2,\n",
              " ('BOS', 'Oh', ','): 2,\n",
              " ('Oh', ',', 'algoritmo'): 2,\n",
              " (',', 'algoritmo', 'EOS'): 2,\n",
              " ('BOS', 'S√©', 'que'): 2,\n",
              " ('S√©', 'que', 'lo'): 2,\n",
              " ('que', 'lo', 'sabes'): 2,\n",
              " ('lo', 'sabes', 'mejor'): 2,\n",
              " ('sabes', 'mejor', 'EOS'): 2,\n",
              " ('BOS', 'Incluso', 'que'): 2,\n",
              " ('Incluso', 'que', 'yo'): 2,\n",
              " ('que', 'yo', 'mismo'): 2,\n",
              " ('yo', 'mismo', 'EOS'): 2,\n",
              " ('BOS', '[', 'Verso'): 4,\n",
              " ('[', 'Verso', '1'): 1,\n",
              " ('Verso', '1', ':'): 1,\n",
              " ('1', ':', 'Nora'): 1,\n",
              " (':', 'Nora', 'Erez'): 2,\n",
              " ('BOS', 'Wait', ','): 1,\n",
              " ('Wait', ',', 'what'): 1,\n",
              " (',', 'what', \"'s\"): 1,\n",
              " ('what', \"'s\", 'that'): 1,\n",
              " (\"'s\", 'that', 'money'): 1,\n",
              " ('that', 'money', 'that'): 1,\n",
              " ('money', 'that', 'you'): 1,\n",
              " ('that', 'you', 'spent'): 1,\n",
              " ('you', 'spent', '?'): 1,\n",
              " ('spent', '?', 'EOS'): 1,\n",
              " ('BOS', 'What', \"'s\"): 1,\n",
              " ('What', \"'s\", 'that'): 1,\n",
              " (\"'s\", 'that', 'sitting'): 1,\n",
              " ('that', 'sitting', 'on'): 1,\n",
              " ('sitting', 'on', 'your'): 1,\n",
              " ('on', 'your', 'plate'): 1,\n",
              " ('your', 'plate', '?'): 1,\n",
              " ('plate', '?', 'EOS'): 1,\n",
              " ('BOS', 'Do', 'you'): 1,\n",
              " ('Do', 'you', 'want'): 1,\n",
              " ('you', 'want', 'what'): 1,\n",
              " ('want', 'what', 'you'): 1,\n",
              " ('what', 'you', \"'ve\"): 1,\n",
              " ('you', \"'ve\", 'been'): 1,\n",
              " (\"'ve\", 'been', 'fed'): 1,\n",
              " ('been', 'fed', '?'): 1,\n",
              " ('fed', '?', 'EOS'): 1,\n",
              " ('BOS', 'Are', 'you'): 1,\n",
              " ('Are', 'you', 'the'): 1,\n",
              " ('you', 'the', 'fish'): 1,\n",
              " ('the', 'fish', 'or'): 1,\n",
              " ('fish', 'or', 'bait'): 1,\n",
              " ('or', 'bait', '?'): 1,\n",
              " ('bait', '?', 'EOS'): 1,\n",
              " ('BOS', 'Mmm', ','): 1,\n",
              " ('Mmm', ',', 'I'): 1,\n",
              " (',', 'I', \"'m\"): 1,\n",
              " ('I', \"'m\", 'on'): 1,\n",
              " (\"'m\", 'on', 'the'): 1,\n",
              " ('on', 'the', 'top'): 1,\n",
              " ('the', 'top', 'of'): 1,\n",
              " ('top', 'of', 'the'): 1,\n",
              " ('of', 'the', 'roof'): 1,\n",
              " ('the', 'roof', 'and'): 1,\n",
              " ('roof', 'and', 'I'): 1,\n",
              " ('and', 'I', 'feel'): 1,\n",
              " ('I', 'feel', 'like'): 1,\n",
              " ('feel', 'like', 'a'): 1,\n",
              " ('like', 'a', 'jail'): 1,\n",
              " ('a', 'jail', 'EOS'): 1,\n",
              " ('BOS', 'Rather', 'not'): 1,\n",
              " ('Rather', 'not', 'pay'): 1,\n",
              " ('not', 'pay', 'the'): 1,\n",
              " ('pay', 'the', 'bail'): 1,\n",
              " ('the', 'bail', 'EOS'): 1,\n",
              " ('BOS', 'To', 'dangerous'): 1,\n",
              " ('To', 'dangerous', 'people'): 1,\n",
              " ('dangerous', 'people', 'with'): 1,\n",
              " ('people', 'with', 'blood'): 1,\n",
              " ('with', 'blood', 'on'): 1,\n",
              " ('blood', 'on', 'their'): 1,\n",
              " ('on', 'their', 'faces'): 1,\n",
              " ('their', 'faces', 'EOS'): 1,\n",
              " ('BOS', 'So', 'I'): 1,\n",
              " ('So', 'I', \"'m\"): 1,\n",
              " ('I', \"'m\", 'sharing'): 1,\n",
              " (\"'m\", 'sharing', 'a'): 1,\n",
              " ('sharing', 'a', 'cell'): 1,\n",
              " ('a', 'cell', 'with'): 1,\n",
              " ('cell', 'with', 'the'): 1,\n",
              " ('with', 'the', 'masses'): 1,\n",
              " ('the', 'masses', 'EOS'): 1,\n",
              " ('BOS', 'The', 'underground'): 1,\n",
              " ('The', 'underground', 'always'): 1,\n",
              " ('underground', 'always', 'strive'): 1,\n",
              " ('always', 'strive', 'for'): 1,\n",
              " ('strive', 'for', 'the'): 1,\n",
              " ('for', 'the', 'main'): 1,\n",
              " ('the', 'main', 'EOS'): 1,\n",
              " ('BOS', 'Streaming', 'like'): 1,\n",
              " ('Streaming', 'like', 'Grande'): 1,\n",
              " ('like', 'Grande', \"'s\"): 1,\n",
              " ('Grande', \"'s\", 'big-ass'): 1,\n",
              " (\"'s\", 'big-ass', 'ring'): 1,\n",
              " ('big-ass', 'ring', 'EOS'): 1,\n",
              " ('BOS', 'Screaming', ':'): 1,\n",
              " ('Screaming', ':', 'I'): 1,\n",
              " (':', 'I', \"'ll\"): 1,\n",
              " ('I', \"'ll\", 'write'): 1,\n",
              " (\"'ll\", 'write', 'you'): 1,\n",
              " ('write', 'you', 'out'): 1,\n",
              " ('you', 'out', 'my'): 1,\n",
              " ('out', 'my', 'will'): 1,\n",
              " ('my', 'will', 'EOS'): 1,\n",
              " ('BOS', 'Conscious', 'is'): 2,\n",
              " ('Conscious', 'is', 'free'): 2,\n",
              " ('is', 'free', ','): 2,\n",
              " ('free', ',', 'but'): 2,\n",
              " (',', 'but', 'not'): 2,\n",
              " ('but', 'not', 'the'): 2,\n",
              " ('not', 'the', 'will'): 2,\n",
              " ('the', 'will', 'EOS'): 2,\n",
              " ('BOS', 'You', 'might'): 1,\n",
              " ('You', 'might', 'also'): 1,\n",
              " ('might', 'also', 'like'): 1,\n",
              " ('also', 'like', 'EOS'): 1,\n",
              " ('BOS', 'Amor', 'al'): 1,\n",
              " ('Amor', 'al', 'Arte'): 1,\n",
              " ('al', 'Arte', 'EOS'): 1,\n",
              " ('BOS', 'Jorge', 'Drexler'): 3,\n",
              " ('Jorge', 'Drexler', 'EOS'): 3,\n",
              " ('BOS', 'Tinta', 'y'): 1,\n",
              " ('Tinta', 'y', 'Tiempo'): 1,\n",
              " ('y', 'Tiempo', 'EOS'): 1,\n",
              " ('BOS', 'Asilo', 'EOS'): 1,\n",
              " ('BOS', '[', 'Pre-Estribillo'): 1,\n",
              " ('[', 'Pre-Estribillo', ':'): 1,\n",
              " ('Pre-Estribillo', ':', 'Nora'): 1,\n",
              " ('BOS', 'So', 'if'): 1,\n",
              " ('So', 'if', 'you'): 1,\n",
              " ('if', 'you', 'want'): 1,\n",
              " ('you', 'want', 'me'): 1,\n",
              " ('want', 'me', 'to'): 1,\n",
              " ('me', 'to', 'want'): 1,\n",
              " ('to', 'want', 'what'): 1,\n",
              " ('want', 'what', 'I'): 1,\n",
              " ('what', 'I', 'believe'): 1,\n",
              " ('I', 'believe', 'that'): 1,\n",
              " ('believe', 'that', 'I'): 1,\n",
              " ('that', 'I', 'want'): 1,\n",
              " ('I', 'want', 'EOS'): 1,\n",
              " ('BOS', 'Can', 'I'): 1,\n",
              " ('Can', 'I', 'choose'): 1,\n",
              " ('I', 'choose', 'to'): 1,\n",
              " ('choose', 'to', 'quit'): 1,\n",
              " ('to', 'quit', '?'): 1,\n",
              " ('quit', '?', 'EOS'): 1,\n",
              " ('[', 'Verso', '2'): 1,\n",
              " ('Verso', '2', ':'): 1,\n",
              " ('2', ':', 'Jorge'): 1,\n",
              " ('BOS', 'Por', 'ejemplo'): 1,\n",
              " ('Por', 'ejemplo', ','): 1,\n",
              " ('ejemplo', ',', 'esta'): 1,\n",
              " (',', 'esta', 'canci√≥n'): 1,\n",
              " ('esta', 'canci√≥n', 'EOS'): 1,\n",
              " ('BOS', '¬øQu√©', 'algoritmo'): 1,\n",
              " ('¬øQu√©', 'algoritmo', 'la'): 1,\n",
              " ('algoritmo', 'la', 'pari√≥'): 1,\n",
              " ('la', 'pari√≥', '?'): 1,\n",
              " ('pari√≥', '?', 'EOS'): 1,\n",
              " ('BOS', 'Me', 'pregunto'): 1,\n",
              " ('Me', 'pregunto', 'si'): 1,\n",
              " ('pregunto', 'si', 'fui'): 1,\n",
              " ('si', 'fui', 'yo'): 1,\n",
              " ('fui', 'yo', 'EOS'): 1,\n",
              " ('BOS', '¬øLa', 'elegiste'): 1,\n",
              " ('¬øLa', 'elegiste', 'o'): 1,\n",
              " ('elegiste', 'o', 'te'): 1,\n",
              " ('o', 'te', 'eligi√≥'): 1,\n",
              " ('te', 'eligi√≥', '?'): 1,\n",
              " ('eligi√≥', '?', 'EOS'): 1,\n",
              " ('[', 'Verso', '3'): 1,\n",
              " ('Verso', '3', ':'): 1,\n",
              " ('3', ':', 'Jorge'): 1,\n",
              " ('BOS', 'Dios', 'era'): 1,\n",
              " ('Dios', 'era', 'la'): 1,\n",
              " ('era', 'la', 'letra'): 1,\n",
              " ('la', 'letra', 'chica'): 1,\n",
              " ('letra', 'chica', 'al'): 1,\n",
              " ('chica', 'al', 'final'): 1,\n",
              " ('al', 'final', 'del'): 1,\n",
              " ('final', 'del', 'papel'): 1,\n",
              " ('del', 'papel', 'EOS'): 1,\n",
              " ('BOS', 'Ya', 'no'): 1,\n",
              " ('Ya', 'no', 'contamos'): 1,\n",
              " ('no', 'contamos', 'con'): 1,\n",
              " ('contamos', 'con', '√âl'): 1,\n",
              " ('con', '√âl', 'EOS'): 1,\n",
              " ('BOS', 'Fin', 'de'): 1,\n",
              " ('Fin', 'de', 'la'): 1,\n",
              " ('de', 'la', 'Luna'): 1,\n",
              " ('la', 'Luna', 'de'): 1,\n",
              " ('Luna', 'de', 'miel'): 1,\n",
              " ('de', 'miel', 'EOS'): 1,\n",
              " ('BOS', 'Y', 'el'): 2,\n",
              " ('Y', 'el', 'libre'): 1,\n",
              " ('el', 'libre', 'albedr√≠o'): 1,\n",
              " ('libre', 'albedr√≠o', 'es'): 1,\n",
              " ('albedr√≠o', 'es', 'un'): 1,\n",
              " ('es', 'un', 'cauce'): 1,\n",
              " ('un', 'cauce', 'vac√≠o'): 1,\n",
              " ('cauce', 'vac√≠o', 'EOS'): 1,\n",
              " ('BOS', 'Un', 'barco'): 1,\n",
              " ('Un', 'barco', 'que'): 1,\n",
              " ('barco', 'que', 'no'): 1,\n",
              " ('que', 'no', 'tiene'): 1,\n",
              " ('no', 'tiene', 'r√≠o'): 1,\n",
              " ('tiene', 'r√≠o', 'EOS'): 1,\n",
              " ('BOS', 'Ni', 'timonel'): 1,\n",
              " ('Ni', 'timonel', 'EOS'): 1,\n",
              " ('[', 'Verso', '4'): 1,\n",
              " ('Verso', '4', ':'): 1,\n",
              " ('4', ':', 'Jorge'): 1,\n",
              " ('BOS', 'Todos', 'aplauden'): 1,\n",
              " ('Todos', 'aplauden', ','): 1,\n",
              " ('aplauden', ',', 't√∫'): 1,\n",
              " (',', 't√∫', 'tambi√©n'): 1,\n",
              " ('t√∫', 'tambi√©n', 'EOS'): 1,\n",
              " ('BOS', 'Pero', 'no'): 1,\n",
              " ('Pero', 'no', 'queda'): 1,\n",
              " ('no', 'queda', 'claro'): 1,\n",
              " ('queda', 'claro', 'qui√©n'): 1,\n",
              " ('claro', 'qui√©n', 'EOS'): 1,\n",
              " ('BOS', 'Tiene', 'del'): 1,\n",
              " ('Tiene', 'del', 'mango'): 1,\n",
              " ('del', 'mango', 'a'): 1,\n",
              " ('mango', 'a', 'la'): 1,\n",
              " ('a', 'la', 'sart√©n'): 1,\n",
              " ('la', 'sart√©n', 'EOS'): 1,\n",
              " ('BOS', 'Del', 'sacrificio'): 1,\n",
              " ('Del', 'sacrificio', 'EOS'): 1,\n",
              " ('BOS', 'Piel', 'o'): 1,\n",
              " ('Piel', 'o', 'silicio'): 1,\n",
              " ('o', 'silicio', 'EOS'): 1,\n",
              " ('Y', 'el', 'precipicio'): 1,\n",
              " ('el', 'precipicio', 'EOS'): 1,\n",
              " ('BOS', 'Dice', ':'): 1,\n",
              " ('Dice', ':', 'Ven'): 1,\n",
              " (':', 'Ven', ','): 1,\n",
              " ('Ven', ',', 'ven'): 1,\n",
              " (',', 'ven', ','): 1,\n",
              " ('ven', ',', 'ven'): 1,\n",
              " (',', 'ven', 'EOS'): 1,\n",
              " ('BOS', '(', 'Dime'): 1,\n",
              " ('(', 'Dime', 'qu√©'): 1,\n",
              " ('debo', 'cantar', ')'): 1,\n",
              " ('cantar', ')', 'EOS'): 1}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgEpVPj21fs"
      },
      "source": [
        "Debe mostrar que su m√©todo funciona para $N = 1,2,3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMzLfBLBk-i7"
      },
      "source": [
        "## P7. Perplexity (1 punto)\n",
        "\n",
        "En esta secci√≥n evaluar√°n su modelo de n-gramas y determinar√°n la probabilidad de oraciones y la perplejidad con un conjunto de test. Recuerde que la perplejidad se define de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\\text{Perplexity} = 2^{-l} \\quad \\quad l = \\frac{1}{M} \\sum_{i=1}^{m} \\log p(s_i)\n",
        "$$\n",
        "\n",
        "con $m$ el n√∫mero de oraciones del corpus y $M$ el tama√±o del vocabulario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tas4KYhZ28_C"
      },
      "source": [
        "### 7.a Obtener probabilidades (0.5 puntos)\n",
        "\n",
        "En esta secci√≥n implementar√° una funci√≥n que determine la probabilidad de una oraci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYH0ScM44Jrb"
      },
      "source": [
        "Defina una funci√≥n que reciba una oraci√≥n, un diccionario con n-gramas y el valor de $n$. La funci√≥n debe entregar la probabilidad de cualquier oraci√≥n.\n",
        "\n",
        "**Hint**: No olvide los posibles casos borde, como palabras fuera del vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "aWGsq22H4Sxz"
      },
      "outputs": [],
      "source": [
        "def get_probability(sentence, ngram_model, n):\n",
        "    if len(sentence) < n:\n",
        "        return 1e-8\n",
        "\n",
        "    min_prob = 1e-8\n",
        "    probs = []\n",
        "\n",
        "    for i in range(len(sentence) - n + 1):\n",
        "        ngram = tuple(sentence[i:i + n])\n",
        "        prefix = ngram[:-1]\n",
        "\n",
        "        count_ngram = ngram_model.get(ngram, 0)\n",
        "        count_prefix = sum(v for k, v in ngram_model.items() if k[:-1] == prefix)\n",
        "\n",
        "        p = count_ngram / count_prefix if count_prefix > 0 else min_prob\n",
        "        probs.append(max(p, min_prob))\n",
        "\n",
        "    return float(np.prod(probs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1UkfOz75W_P"
      },
      "source": [
        "Pruebe su funci√≥n con oraciones frecuentes y comente sus resultados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngram_model = n_grams(train_corpus, n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8461538461538461"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(word_tokenize(\"BOS ¬øQui√©n quiere que yo quiera lo que creo que quiero ? EOS\"), ngram_model, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0000000000000001e-40"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(word_tokenize(\"Existe algo as√≠ en el texto realmente\"), ngram_model, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1e-08"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_probability(word_tokenize(\"Jorge Drexler  \"), ngram_model, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las tres oraciones evaluadas ilustran distintos comportamientos del modelo trigram: la primera, altamente frecuente en el corpus, obtuvo una probabilidad elevada debido a que todos sus trigramas est√°n presentes en el modelo; la segunda, inexistente en el entrenamiento, fue penalizada severamente con una probabilidad extremadamente baja por contener solo trigramas no observados; la tercera, al ser demasiado corta para formar trigramas, activa un caso borde y retorna directamente la probabilidad m√≠nima asignada por defecto (1e-08)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfnIFV7F3eOL"
      },
      "source": [
        "### 7.b Perplexity en conjunto de test (0.5 puntos)\n",
        "\n",
        "En esta sub-secci√≥n deber√° calcular la perplejidad del corpus de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N21I_mPl5Cqx"
      },
      "source": [
        "Defina una funci√≥n que reciba un corpus de test y retorne la perplexity (ver clases del curso). Utilice la funci√≥n de la secci√≥n anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VC4Vbk3q5LsY"
      },
      "outputs": [],
      "source": [
        "def get_perplexity(corpus, n):\n",
        "    ngram_model = n_grams(train_corpus, n)\n",
        "\n",
        "    total_log_probs = []\n",
        "    total_tokens = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        tokens = word_tokenize(f'BOS {sentence.strip()} EOS')\n",
        "        total_tokens += len(tokens)\n",
        "        prob = get_probability(tokens, ngram_model, n)\n",
        "        log_prob = np.log2(prob) if prob > 0 else np.log2(1e-8)\n",
        "        total_log_probs.append(log_prob)\n",
        "\n",
        "    entropy = -np.sum(total_log_probs) / total_tokens\n",
        "    return float(2 ** entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OAjpRDoG5sUJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13.98616718737452"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_perplexity(test_corpus, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhc07wXM5gyI"
      },
      "source": [
        "Nosotros interpretamos el valor de perplexity ‚âà 13,99 como una medida del grado de incertidumbre promedio que el modelo trigramas manifiesta al predecir las palabras del corpus de test. Este valor indica que, al enfrentarse a las secuencias ling√º√≠sticas del conjunto de prueba, el modelo considera en promedio unas 14 opciones posibles como continuaciones plausibles. La magnitud del resultado sugiere que el modelo logra capturar una porci√≥n significativa de las regularidades del lenguaje en el corpus, aunque a√∫n conserva un margen de dispersi√≥n en sus predicciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNsmR4OPQQX"
      },
      "source": [
        "## P8. Interpolaci√≥n Lineal (0.5 puntos)\n",
        "\n",
        "Cree una funci√≥n que obtenga la probabilidad de una oraci√≥n interpolando linealmente modelos de unigrama, bigrama y trigrama ponderados por $\\lambda_1, \\lambda_2$ y $\\lambda_3$ respectivamente. Para esto use las funciones que cre√≥ anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "X7kcWusAPPv5"
      },
      "outputs": [],
      "source": [
        "def get_probability_lineal_interpol(sentence, corpus, l_1, l_2, l_3):\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from collections import Counter\n",
        "    import numpy as np\n",
        "\n",
        "    assert abs(l_1 + l_2 + l_3 - 1.0) < 1e-6, \"Los pesos deben sumar 1\"\n",
        "\n",
        "    # Modelos de n-gramas\n",
        "    model_1 = Counter(n_grams(corpus, 1))\n",
        "    model_2 = Counter(n_grams(corpus, 2))\n",
        "    model_3 = Counter(n_grams(corpus, 3))\n",
        "\n",
        "    total_1 = sum(model_1.values())\n",
        "    tokens = word_tokenize(f'BOS {sentence.strip()} EOS')\n",
        "    min_prob = 1e-8\n",
        "    probs = []\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "        w1 = tokens[i]\n",
        "        w2 = tokens[i - 1] if i >= 1 else None\n",
        "        w3 = tokens[i - 2] if i >= 2 else None\n",
        "\n",
        "        # Unigrama\n",
        "        p1 = model_1.get((w1,), 0) / total_1 if (w1,) in model_1 else 0\n",
        "\n",
        "        # Bigrama\n",
        "        if w2:\n",
        "            prefix_count = sum(v for k, v in model_2.items() if k[0] == w2)\n",
        "            p2 = model_2.get((w2, w1), 0) / prefix_count if prefix_count > 0 else 0\n",
        "        else:\n",
        "            p2 = 0\n",
        "\n",
        "        # Trigrama\n",
        "        if w2 and w3:\n",
        "            trigram_prefix = (w3, w2)\n",
        "            prefix_count = sum(v for k, v in model_3.items() if k[:2] == trigram_prefix)\n",
        "            p3 = model_3.get((w3, w2, w1), 0) / prefix_count if prefix_count > 0 else 0\n",
        "        else:\n",
        "            p3 = 0\n",
        "\n",
        "        interpolated = l_1 * p1 + l_2 * p2 + l_3 * p3\n",
        "        probs.append(max(interpolated, min_prob))\n",
        "\n",
        "    return float(np.prod(probs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1J_E77RQp3"
      },
      "source": [
        "Defina una funci√≥n para calcular la perplejidad de un corpus con interpolaci√≥n lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oAS94E1UROkg"
      },
      "outputs": [],
      "source": [
        "def get_pp_interpol(corpus, l_1, l_2, l_3):\n",
        "    \"\"\"\n",
        "    Calcula la perplejidad de un corpus de prueba utilizando interpolaci√≥n lineal.\n",
        "\n",
        "    Args:\n",
        "        corpus (list[str]): Lista de oraciones (test_corpus).\n",
        "        l_1, l_2, l_3 (float): Pesos para unigramas, bigramas y trigramas (deben sumar 1).\n",
        "\n",
        "    Returns:\n",
        "        float: Valor de perplexity del corpus con interpolaci√≥n.\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    from nltk.tokenize import word_tokenize\n",
        "\n",
        "    total_log_prob = 0.0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for sentence in corpus:\n",
        "        tokens = word_tokenize(f'BOS {sentence.strip()} EOS')\n",
        "        total_tokens += len(tokens)\n",
        "        prob = get_probability_lineal_interpol(sentence, train_corpus, l_1, l_2, l_3)\n",
        "        log_prob = np.log2(prob) if prob > 0 else np.log2(1e-8)\n",
        "        total_log_prob += log_prob\n",
        "\n",
        "    entropy = - total_log_prob / total_tokens\n",
        "    return float(2 ** entropy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqoX9_o2SHOY"
      },
      "source": [
        "Ahora haga pruebas con distintos valores de $\\lambda_1, \\lambda_2$ y $\\lambda_3$, incluyendo valores extremos (por ejemplo $[1, 0, 0]$). Comente sus resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluaci√≥n valores arbitrarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.76846587140421"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.33, 0.33, 0.34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20.28072362824061"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.1, 0.3, 0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32.268745617881706"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.6, 0.3, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19.689912632063717"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.1, 0.6, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.734592387217653"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0.3, 0.6, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizando estas pruebas es posible apreciar que hay combinaciones de $\\lambda$ que entregan mejores resultados de perplexity que otros. Adem√°s de indicar cual es n-grama que tiene mayor peso en la interpolaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluaci√≥n valores extemos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "OZ6-NA3AOUmq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "782.2597481383283"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 1, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39.35619117450112"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "450.352023599737"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_pp_interpol(test_corpus, 0, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que al asignar el 100% del peso a un solo modelo n-grama, la perplexity var√≠a dr√°sticamente seg√∫n el orden considerado. El modelo de unigramas $(1, 0, 0)$ alcanza una perplexity muy alta ($782.26$), lo que refleja su incapacidad para capturar dependencias contextuales. El bigrama $(0, 1, 0)$ ofrece el mejor desempe√±o ($39.36$), al equilibrar contexto y generalizaci√≥n. En cambio, el trigrama $(0, 0, 1)$ sufre de sobreajuste, con una perplexity elevada ($450.35$), evidenciando que ning√∫n modelo extremo es √≥ptimo por s√≠ solo, y que la interpolaci√≥n es clave para un balance eficaz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Por cuestiones de curiosidad quise saber el valor de todos los posibles valores sin entrar en los decimales tan exactos (aun) as√≠ que dise√±e una funci√≥n que encuentra la mejor interpolaci√≥n dentro de todos los valores posibles de lambda:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_interpolation(test_corpus):\n",
        "    best_perplexity = float('inf')\n",
        "    best_weights = None\n",
        "\n",
        "    for l1 in np.arange(0.0, 1.01, 0.1):\n",
        "        for l2 in np.arange(0.0, 1.01 - l1, 0.1):\n",
        "            l3 = round(1.0 - l1 - l2, 1)\n",
        "            if l3 < 0.0 or l3 > 1.0:\n",
        "                continue\n",
        "            try:\n",
        "                pp = get_pp_interpol(test_corpus, round(l1, 1), round(l2, 1), round(l3, 1))\n",
        "                if pp < best_perplexity:\n",
        "                    best_perplexity = pp\n",
        "                    best_weights = (round(l1, 1), round(l2, 1), round(l3, 1))\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "    return best_perplexity, best_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor perplexity: 19.666278810965135\n",
            "Pesos √≥ptimos: Œª1=0.1, Œª2=0.5, Œª3=0.4\n"
          ]
        }
      ],
      "source": [
        "best_pp, best_lambdas = find_best_interpolation(test_corpus)\n",
        "print(f\"Mejor perplexity: {best_pp}\")\n",
        "print(f\"Pesos √≥ptimos: Œª1={best_lambdas[0]}, Œª2={best_lambdas[1]}, Œª3={best_lambdas[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora con 2 decimales de exactitud:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def refine_best_interpolation(test_corpus, best_weights, step=0.01, delta=0.05):\n",
        "    best_perplexity = float('inf')\n",
        "    best_refined_weights = None\n",
        "\n",
        "    l1_center, l2_center, _ = best_weights\n",
        "\n",
        "    # Definir rangos locales para l1 y l2\n",
        "    l1_range = np.round(np.arange(max(0.0, l1_center - delta), min(1.0, l1_center + delta) + step, step), 2)\n",
        "\n",
        "    for l1 in l1_range:\n",
        "        l2_max = 1.0 - l1\n",
        "        l2_range = np.round(np.arange(max(0.0, l2_center - delta), min(l2_max, l2_center + delta) + step, step), 2)\n",
        "\n",
        "        for l2 in l2_range:\n",
        "            l3 = round(1.0 - l1 - l2, 2)\n",
        "            if l3 < 0.0 or l3 > 1.0:\n",
        "                continue\n",
        "            try:\n",
        "                perplexity = get_pp_interpol(test_corpus, l1, l2, l3)\n",
        "                if perplexity < best_perplexity:\n",
        "                    best_perplexity = perplexity\n",
        "                    best_refined_weights = (l1, l2, l3)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    return best_perplexity, best_refined_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor perplexity refinada: 19.617784454120947\n",
            "Pesos √≥ptimos refinados: Œª1=0.08, Œª2=0.55, Œª3=0.37\n"
          ]
        }
      ],
      "source": [
        "best_pp_1d, best_weights_1d = find_best_interpolation(test_corpus)\n",
        "\n",
        "best_pp_refined, best_weights_refined = refine_best_interpolation(test_corpus, best_weights_1d)\n",
        "\n",
        "print(f\"Mejor perplexity refinada: {best_pp_refined}\")\n",
        "print(f\"Pesos √≥ptimos refinados: Œª1={best_weights_refined[0]}, Œª2={best_weights_refined[1]}, Œª3={best_weights_refined[2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Curiosamente funcion√≥, as√≠ que para este caso, los mejores lambda son Œª1=0.08, Œª2=0.55, Œª3=0.37 para cada modelo de n-grama respectivamente. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
